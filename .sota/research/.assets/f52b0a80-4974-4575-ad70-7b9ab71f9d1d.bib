@inproceedings{10.1145/3417990.3419488,
author = {Schiedermeier, Maximilian},
title = {A Concern-Oriented Software Engineering Methodology for Micro-Service Architectures},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3419488},
doi = {10.1145/3417990.3419488},
abstract = {Component-Based Systems (CBS) allow for the construction of modular, highly scalable software. Decomposing a system into individually maintainable and deployable components enables a targeted replication of performance bottlenecks, and promotes code modularity. Over the last years, the Micro-Service Architecture (MSA) style has become a popular approach to maximize the benefits of CBS. However, MSA introduces new challenges, by imposing a conceptual and technological stack on adherent projects, which require new critical design choices. Throughout my PhD I want to investigate to which extent a systematic reuse of MSA solutions of various granularity can streamline MSA application development by guiding design decisions.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {28},
numpages = {5},
keywords = {representational state transfer, model-driven engineering, micro-service architectures, concern-oriented reuse},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3335484.3335546,
author = {Lin, Pingrong and Lin, Zheyuan and Shi, Xiaoquan},
title = {Research on Optimization of Course Selection System Based on Micro Service and Dynamic Resource Extension},
year = {2019},
isbn = {9781450362788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3335484.3335546},
doi = {10.1145/3335484.3335546},
abstract = {In view of the fact that the course selection system in Colleges and universities has short burst access, large concurrent business and complex business, and combined with the existing course selection system of South China Institute of Software Engineering of Guangzhou University, an optimization scheme based on micro service and dynamic resource extension is constructed. The scheme can solve the problem of low performance of course selection system by building a micro-service architecture, splitting the business services of course selection system, scaling up the cluster of servers, and expanding the resources dynamically. The performance comparison before and after optimization shows that the performance of the course selection system has been greatly improved, and the scheme is feasible and effective.},
booktitle = {Proceedings of the 4th International Conference on Big Data and Computing},
pages = {115–119},
numpages = {5},
keywords = {micro-service, dynamic resource expansion, course selection system},
location = {Guangzhou, China},
series = {ICBDC '19}
}

@article{10.1145/3501297,
author = {Soldani, Jacopo and Brogi, Antonio},
title = {Anomaly Detection and Failure Root Cause Analysis in (Micro) Service-Based Cloud Applications: A Survey},
year = {2022},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3501297},
doi = {10.1145/3501297},
abstract = {The proliferation of services and service interactions within microservices and cloud-native applications, makes it harder to detect failures and to identify their possible root causes, which is, on the other hand crucial to promptly recover and fix applications. Various techniques have been proposed to promptly detect failures based on their symptoms, viz., observing anomalous behaviour in one or more application services, as well as to analyse logs or monitored performance of such services to determine the possible root causes for observed anomalies. The objective of this survey is to provide a structured overview and qualitative analysis of currently available techniques for anomaly detection and root cause analysis in modern multi-service applications. Some open challenges and research directions stemming out from the analysis are also discussed.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {59},
numpages = {39},
keywords = {Microservices, multi-service applications, root cause analysis, failure detection, anomaly detection}
}

@inproceedings{10.1145/3503181.3503196,
author = {Wang, Shuaiyu and Li, Yinsheng},
title = {A Creditworthy Resources Sharing Platform Based on Microservice✱},
year = {2021},
isbn = {9781450395540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503181.3503196},
doi = {10.1145/3503181.3503196},
abstract = {There is a promising business in smart manufacturing to share owners’ technical resources such as equipment, software, or capabilities. The resources are developed and provided as open services, which are requested by clients to compose new applications or improve existing applications. To implement this sharing business, a life-cycle framework is proposed to classify, identify, develop, publish, provision, operate, and compose the services. A creditworthy resources sharing platform has been developed to testify the framework. With the platform, micro-service techniques are applied to improve the services’ performance both in a run-time environment and collaborative development. And block-chain techniques are applied to improve the services’ transaction data proprietary and security.},
booktitle = {5th International Conference on Crowd Science and Engineering},
pages = {88–94},
numpages = {7},
keywords = {cloud, microservice, creditworthiness, smart contracts, blockchain, container, smart manufacturing},
location = {Jinan, China},
series = {ICCSE '21}
}

@inproceedings{10.1145/3457913.3457939,
author = {Wei, Yuyang and Yu, Yijun and Pan, Minxue and Zhang, Tian},
title = {A Feature Table Approach to Decomposing Monolithic Applications into Microservices},
year = {2020},
isbn = {9781450388191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457913.3457939},
doi = {10.1145/3457913.3457939},
abstract = {Microservice architecture refers to the use of numerous small-scale and independently deployed services, instead of encapsulating all functions into one monolith. It has been a challenge in software engineering to decompose a monolithic system into smaller parts. In this paper, we propose the Feature Table approach, a structured approach to service decomposition based on the correlation between functional features and microservices: (1) we defined the concept of Feature Cards and 12 instances of such cards; (2) we formulated Decomposition Rules to decompose monolithic applications; (3) we designed the Feature Table Analysis Tool to provide semi-automatic analysis for identification of microservices; and (4) we formulated Mapping Rules to help developers implement microservice candidates. We performed a case study on Cargo Tracking System to validate our microservice-oriented decomposition approach. Cargo Tracking System is a typical case that has been decomposed by other related methods (dataflow-driven approach, Service Cutter, and API Analysis). Through comparison with the related methods in terms of specific coupling and cohesion metrics, the results show that the proposed Feature Table approach can deliver more reasonable microservice candidates, which are feasible in implementation with semi-automatic support.},
booktitle = {Proceedings of the 12th Asia-Pacific Symposium on Internetware},
pages = {21–30},
numpages = {10},
keywords = {Microservices, microservice architecture, monolith decomposition},
location = {Singapore, Singapore},
series = {Internetware '20}
}

@inproceedings{10.1145/3412841.3442016,
author = {Brito, Miguel and Cunha, J\'{a}come and Saraiva, Jo\~{a}o},
title = {Identification of Microservices from Monolithic Applications through Topic Modelling},
year = {2021},
isbn = {9781450381048},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3412841.3442016},
doi = {10.1145/3412841.3442016},
abstract = {Microservices emerged as one of the most popular architectural patterns in the recent years given the increased need to scale, grow and flexibilize software projects accompanied by the growth in cloud computing and DevOps. Many software applications are being submitted to a process of migration from its monolithic architecture to a more modular, scalable and flexible architecture of microservices. This process is slow and, depending on the project's complexity, it may take months or even years to complete.This paper proposes a new approach on microservice identification by resorting to topic modelling in order to identify services according to domain terms. This approach in combination with clustering techniques produces a set of services based on the original software. The proposed methodology is implemented as an open-source tool for exploration of monolithic architectures and identification of microservices. A quantitative analysis using the state of the art metrics on independence of functionality and modularity of services was conducted on 200 open-source projects collected from GitHub. Cohesion at message and domain level metrics' showed medians of roughly 0.6. Interfaces per service exhibited a median of 1.5 with a compact interquartile range. Structural and conceptual modularity revealed medians of 0.2 and 0.4 respectively.Our first results are positive demonstrating beneficial identification of services due to overall metrics' results.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
pages = {1409–1418},
numpages = {10},
location = {Virtual Event, Republic of Korea},
series = {SAC '21}
}

@inproceedings{10.1145/3524304.3524306,
author = {Ding, Xiang and Zhang, Cheng},
title = {How Can We Cope with the Impact of Microservice Architecture Smells?},
year = {2022},
isbn = {9781450385770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524304.3524306},
doi = {10.1145/3524304.3524306},
abstract = {Context: Software Architecture Smells (AS) are potential software structure problems and always impact software quality negatively. And with the development of Microservice architecture, the Microservice Architecture Smells (MAS) have been attracting more and more attention. The software scholars and developers have discovered the influence of MAS and performed some researches on them. However, the definition and category of MAS are still ambiguous.Objects: This paper aims to clarify the specific MAS categories and their definitions, and then further explores the issues caused by MAS in the migration process from a monolithic system to Microservice.Method: We performed a comprehensive systematic literature review about MAS. Specifically, we explored 13 white and 10 grey literature in detail to get MAS information by using the quantitative research method. To explore the issues that influence the migration process from a monolithic system to Microservice, we used the meta-ethnography qualitative research method to extract relevant information and get six three-order translations.Results: This study defined 22 Microservice Architecture Smells and classified them into five categories, namely Design, Deployment, Monitor &amp; Log, Communication and Team &amp; Tool, based on their characteristics. Simultaneously, the issues that influence the migration process are proposed, including service cutting, databases, communication, team and techniques. Finally, we matched the MAS to the issues they caused in the migration process and recommended solutions to these issues.},
booktitle = {2022 11th International Conference on Software and Computer Applications},
pages = {8–14},
numpages = {7},
keywords = {Microservice Architecture Smells, Systematic Literature Review, smell impact, meta-ethnography},
location = {Melaka, Malaysia},
series = {ICSCA 2022}
}

@inproceedings{10.1145/3387906.3388625,
author = {Pigazzini, Ilaria and Fontana, Francesca Arcelli and Lenarduzzi, Valentina and Taibi, Davide},
title = {Towards Microservice Smells Detection},
year = {2020},
isbn = {9781450379601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387906.3388625},
doi = {10.1145/3387906.3388625},
abstract = {With the adoption of microservices architectural styles, practitioners started noticing increasing pitfalls in managing and maintaining such architectures, with the risk of introducing architectural debt. Previous studies identified different microservice smells (also named anti-patterns) that harm microservices architectures. However, according to our knowledge, there are no tools that can automatically detect microservice smells, so their identification is left to the experience of the developer. In this paper, we extend an existing tool developed for the detection of architectural smells to explore microservices architecture through the detection of three microservice smells: Cyclic Dependencies, Hard-Coded Endpoints, and Shared Persistence. We detected the smells on five open-source projects implemented with microservices and manually validated the precision of the detection results. This work aims to open new perspectives on facing and studying architectural debt in the field of microservices architectures.},
booktitle = {Proceedings of the 3rd International Conference on Technical Debt},
pages = {92–97},
numpages = {6},
keywords = {microservices, microservice bad smells detection, anti-patterns},
location = {Seoul, Republic of Korea},
series = {TechDebt '20}
}

@article{10.1145/3461011,
author = {Chondamrongkul, Nacha and Sun, Jing and Warren, Ian},
title = {Software Architectural Migration: An Automated Planning Approach},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3461011},
doi = {10.1145/3461011},
abstract = {Software architectural designs are usually changed over time to support emerging technologies and to adhere to new principles. Architectural migration is an important activity that helps to transform the architectural styles applied during a system’s design with the result of modernising the system. If not performed correctly, this process could lead to potential system failures. This article presents an automated approach to refactoring architectural design and to planning the evolution process. With our solution, the architectural design can be refactored, ensuring that system functionality is preserved. Furthermore, the architectural migration process allows the system to be safely and incrementally transformed. We have evaluated our approach with five real-world software applications. The results prove the effectiveness of our approach and identify factors that impact the performance of architectural verification and migration planning. An interesting finding is that planning algorithms generate migration plans that differ in term of their relative efficiency.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jul},
articleno = {50},
numpages = {35},
keywords = {Software architecture, microservice, software modernisation, architectural migration, Blockchain}
}

@inproceedings{10.1145/3275219.3275230,
author = {Ren, Zhongshan and Wang, Wei and Wu, Guoquan and Gao, Chushu and Chen, Wei and Wei, Jun and Huang, Tao},
title = {Migrating Web Applications from Monolithic Structure to Microservices Architecture},
year = {2018},
isbn = {9781450365901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3275219.3275230},
doi = {10.1145/3275219.3275230},
abstract = {In the traditional software development and deployment, the centralized monolithic is always adopted, as the modules are tightly coupled, which caused many inconvenience in software DevOps. The modules with bottlenecks in monolithic application cannot be extend separately as the application is an integral part, and different module cannot use different technology stack. To prolong the lifecycle of the monolithic applications, its need to migrated it to microservice architecture. Due to the complex logic and large number of third party framework libraries depended, get an accurate comprehensive of the application characteristics is challenging. The existing research mostly based on the static characteristics, lack of consideration of the runtime dynamic characteristics, and the completeness and accuracy of the static analysis is inadequate. To resolve above problems, we combined static and dynamic analysis to get static structure and runtime behavior characteristics of monolithic application. We employed the coupling among functions to evaluate the degree of dependence, and through function clustering to achieve the migration of legacy monolithic applications and its data to microservices architecture. Through the empirical study of migrate the typical legacy project to microservices, it is proved that we proposed method can offer precise guidance and assistance in the migration procedure. Experiments show that the method has high accuracy and low performance cost.},
booktitle = {Proceedings of the 10th Asia-Pacific Symposium on Internetware},
articleno = {7},
numpages = {10},
keywords = {function clustering, microservices, application migration, monolithic application},
location = {Beijing, China},
series = {Internetware '18}
}

@inproceedings{10.1145/3483899.3483908,
author = {Santos, Ana and Paula, Hugo},
title = {Microservice Decomposition and Evaluation Using Dependency Graph and Silhouette Coefficient},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483908},
doi = {10.1145/3483899.3483908},
abstract = {The benefits provided by microservices architecture in some application scenarios are a motivating factor for organizations to migrate their monoliths to this architecture. Extracting microservices from existing monolithic code bases presents a key challenge in this context, and there is a lack of tools that automate not only the decomposition processes but also the evaluation of the resulting architecture. This work presents a new approach for microservice decomposition that analyzes source code of a monolithic application and, with the combined use of approaches in the literature, suggests parts to be extracted in microservices considering the artifacts: classes, methods and/or history of modifications. The quality of the microservices’ suggestions are assessed, quantitatively, through the silhouette coefficient, a quality metric used in clustering analysis, and the microservice granularity. A tool was developed to automate the process of microservice decomposition for Java repositories. As a result, it was observed that the tool generated clusters with satisfactory results and can be used as an auxiliary instrument by experts during the migration process from monolithic architecture to microservices.},
booktitle = {15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {51–60},
numpages = {10},
keywords = {microservices, monolithic application, decomposition},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@article{10.1145/3183628.3183631,
author = {Cerny, Tomas and Donahoo, Michael J. and Trnka, Michal},
title = {Contextual Understanding of Microservice Architecture: Current and Future Directions},
year = {2018},
issue_date = {December 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1559-6915},
url = {https://doi.org/10.1145/3183628.3183631},
doi = {10.1145/3183628.3183631},
abstract = {Current industry trends in enterprise architectures indicate movement from Service-Oriented Architecture (SOA) to Microservices. By understanding the key differences between these two approaches and their features, we can design a more effective Microservice architecture by avoiding SOA pitfalls. To do this, we must know why this shift is happening and how key SOA functionality is addressed by key features of the Microservice-based system. Unfortunately, Microservices do not address all SOA shortcomings. In addition, Microservices introduce new challenges. This work provides a detailed analysis of the differences between these two architectures and their features. Next, we describe both research and industry perspectives on the strengths and weaknesses of both architectural directions. Finally, we perform a systematic mapping study related to Microservice research, identifying interest and challenges in multiple categories from a range of recent research.},
journal = {SIGAPP Appl. Comput. Rev.},
month = {jan},
pages = {29–45},
numpages = {17},
keywords = {SOA, architectures, self-contained systems, systematic mapping study, survey, microservices}
}

@inproceedings{10.1145/3468264.3473915,
author = {Kalia, Anup K. and Xiao, Jin and Krishna, Rahul and Sinha, Saurabh and Vukovic, Maja and Banerjee, Debasish},
title = {Mono2Micro: A Practical and Effective Tool for Decomposing Monolithic Java Applications to Microservices},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473915},
doi = {10.1145/3468264.3473915},
abstract = {In migrating production workloads to cloud, enterprises often face the daunting task of evolving monolithic applications toward a microservice architecture. At IBM, we developed a tool called Mono2Micro to assist with this challenging task. Mono2Micro performs spatio-temporal decomposition, leveraging well-defined business use cases and runtime call relations to create functionally cohesive partitioning of application classes. Our preliminary evaluation of Mono2Micro showed promising results. How well does Mono2Micro perform against other decomposition techniques, and how do practitioners perceive the tool? This paper describes the technical foundations of Mono2Micro and presents results to answer these two questions. To answer the first question, we evaluated Mono2Micro against four existing techniques on a set of open-source and proprietary Java applications and using different metrics to assess the quality of decomposition and tool’s efficiency. Our results show that Mono2Micro significantly outperforms state-of-the-art baselines in specific metrics well-defined for the problem domain. To answer the second question, we conducted a survey of twenty-one practitioners in various industry roles who have used Mono2Micro. This study highlights several benefits of the tool, interesting practitioner perceptions, and scope for further improvements. Overall, these results show that Mono2Micro can provide a valuable aid to practitioners in creating functionally cohesive and explainable microservice decompositions.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1214–1224},
numpages = {11},
keywords = {clustering, microservices, dynamic analysis},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@inproceedings{10.1145/3491204.3527462,
author = {V, Thrivikraman and Dixit, Vishnu R. and S, Nikhil Ram and Gowda, Vikas K. and Vasudevan, Santhosh Kumar and Kalambur, Subramaniam},
title = {MiSeRTrace: Kernel-Level Request Tracing for Microservice Visibility},
year = {2022},
isbn = {9781450391597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491204.3527462},
doi = {10.1145/3491204.3527462},
abstract = {With the evolution of microservice applications, the underlying architectures have become increasingly complex compared to their monolith counterparts. This mainly brings in the challenge of observability. By providing a deeper understanding into the functioning of distributed applications, observability enables improving the performance of the system by obtaining a view of the bottlenecks in the implementation. The observability provided by currently existing tools that perform dynamic tracing on distributed applications is limited to the user-space and requires the application to be instrumented to track request flows. In this paper, we present a new open-source framework MiSeRTrace that can trace the end-to-end path of requests entering a microservice application at the kernel space without requiring instrumentation or modification of the application. Observability at the comprehensiveness of the kernel space allows breaking down of various steps in activities such as network transfers and IO tasks, thus enabling root cause based performance analysis and accurate identification of hotspots. MiSeRTrace supports tracing user-enabled kernel events provided by frameworks such as bpftrace or ftrace and isolates kernel activity associated with each application request with minimal overheads. We then demonstrate the working of the solution with results on a benchmark microservice application.},
booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
pages = {77–80},
numpages = {4},
keywords = {misertrace, thread state model, microservice, request tracing, kernel tracing},
location = {Bejing, China},
series = {ICPE '22}
}

@inproceedings{10.1145/3098954.3105820,
author = {Fetzer, Christof and Mazzeo, Giovanni and Oliver, John and Romano, Luigi and Verburg, Martijn},
title = {Integrating Reactive Cloud Applications in SERECA},
year = {2017},
isbn = {9781450352574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3098954.3105820},
doi = {10.1145/3098954.3105820},
abstract = {A consolidated trend in designing cloud-based applications is to make use of a reactive microservice architecture, which allows to divide an application in several well-partitioned software units with specific responsibilities. Such an architecture perfectly fits in cloud environments, ensuring a number of advantages (i.e., high availability and scalability, ease of deployment and development). However, the new way of designing cloud applications introduces challenging security threats. Besides the difficulty in monitoring security of the overall distributed application, an important aspect of concern relates to the risk of break the chain of trust established among the different microservices belonging to the application. That is, a compromised single microservice may bring down the other related ones.In this paper, we present the approach pursued in the context of SERECA1 project to secure microservice based applications. We leveraged the new extension of Intel's CPU, namely Software Guard eXtension (SGX), to enhance the security of applications using Eclipse Vert.x, the tool-kit for building reactive cloud applications. We developed an infrastructure composed by several SGX-enabled facilities (e.g. Database, Containers, Coordination Services) to support the process of integration between Intel SGX and micro-service applications. Our platform has been, then, validated through two use cases that made use of the developed secure facilities, i.e., a Critical Infrastructure (CI) monitoring application - having strong requirements in terms of data integrity - and an application for performance analysis of cloud-based services where the confidentiality of data is of main interest.},
booktitle = {Proceedings of the 12th International Conference on Availability, Reliability and Security},
articleno = {39},
numpages = {8},
keywords = {Microservice, Intel SGX, Cloud Security, vert.x},
location = {Reggio Calabria, Italy},
series = {ARES '17}
}

@inproceedings{10.1145/3297280.3297401,
author = {Ibrahim, Amjad and Bozhinoski, Stevica and Pretschner, Alexander},
title = {Attack Graph Generation for Microservice Architecture},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297401},
doi = {10.1145/3297280.3297401},
abstract = {Microservices, which are typically technologically heterogenous and can be deployed automatically, are increasingly dominating service systems. However, with increased utilization of third-party components distributed as images, the potential vulnerabilities in microservice-based systems increase. Based on component dependency, such vulnerabilities can lead to exposing a system's critical assets. Similar problems have been addressed by the computer networks community. In this paper, we propose utilizing attack graphs in the continuous delivery infrastructure of microservices-based systems. To that end, we relate microservices to network nodes and automatically generate attack graphs that help practitioners identify, analyze, and prevent plausible attack paths in their microservice-based container networks. We present a complete solution that can be easily embedded in continuous delivery systems and demonstrate its efficiency and scalability based on real-world use cases.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1235–1242},
numpages = {8},
keywords = {microservices, containers, attack graph generation},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/2851553.2892039,
author = {Knoche, Holger},
title = {Sustaining Runtime Performance While Incrementally Modernizing Transactional Monolithic Software towards Microservices},
year = {2016},
isbn = {9781450340809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851553.2892039},
doi = {10.1145/2851553.2892039},
abstract = {Microservices are a promising target architecture for the modernization of monolithic software. However, breaking up a monolith into services can have a severe impact on performance, especially transactions. Therefore, careful planning of such modernizations with respect to performance is required. This is particularly true for incremental modernizations, which release partially modernized states of the application into production. In this paper, we present a simulation-based approach for sustaining runtime performance during incremental modernizations towards Microservices.},
booktitle = {Proceedings of the 7th ACM/SPEC on International Conference on Performance Engineering},
pages = {121–124},
numpages = {4},
keywords = {microservices, software modernization},
location = {Delft, The Netherlands},
series = {ICPE '16}
}

@inproceedings{10.5555/3511065.3511076,
author = {Yoder, Joseph W. and Merson, Paulo},
title = {Strangler Patterns},
year = {2020},
isbn = {9781941652169},
publisher = {The Hillside Group},
address = {USA},
abstract = {Martin Fowler coined the term "Strangler Application" as a metaphor to describe a way of doing an evolutionary rewrite of a system, keeping it working while you evolve it. The main idea is to gradually create a new system around the edges of the old, letting it grow slowly over several years until the old system is strangled. The microservices architecture style has become very popular, and has been used to apply the strangler application to monolithic service-based systems. This paper describes different strategies (patterns) for applying the strangler application while evolving a monolith to use the microservices architecture style. The main ideas are: Wrap the monolith and protect services and system from change, Start Small and gradually evolve the system (baby steps), Pave the Road making microservices easier to create; Macroservice first then split to Microservice, Add new functionality as microservices, Extract Module / Component to Microservice, and Replace functionality with Microservice. As the system evolve it is common to Proxy Monolith Components and Add Fa\c{c}ade to the microservices},
booktitle = {Proceedings of the 27th Conference on Pattern Languages of Programs},
articleno = {8},
numpages = {25},
keywords = {pattern sequences, evolutionary architecture, pattern scenarios, continuous integration, monolith, architecture, DevOps, strangler, sustainable delivery, software development, patterns, microservices},
location = {Virtual Event},
series = {PLoP '20}
}

@inproceedings{10.1145/3337821.3337857,
author = {Hou, Xiaofeng and Liu, Jiacheng and Li, Chao and Guo, Minyi},
title = {Unleashing the Scalability Potential of Power-Constrained Data Center in the Microservice Era},
year = {2019},
isbn = {9781450362955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337821.3337857},
doi = {10.1145/3337821.3337857},
abstract = {Recent scale-out cloud services have undergone a shift from monolithic applications to microservices by putting each functionality into lightweight software containers. Although traditional data center power optimization frameworks excel at per-server or per-rack management, they can hardly make informed decisions when facing microservices that have different QoS requirements on a per-service basis. In a power-constrained data center, blindly budgeting power usage could lead to a power unbalance issue: microservices on the critical path may not receive adequate power budget. This unavoidably hinders the growth of cloud productivity.To unleash the performance potential of cloud in the microservice era, this paper investigates microservice-aware data center resource management. We model microservice using a bipartite graph and propose a metric called microservice criticality factor (MCF) to measure the overall impact of performance scaling on a microservice from the whole application's perspective. We further devise ServiceFridge, a novel system framework that leverages MCF to jointly orchestrate software containers and control hardware power demand. Our detailed case study on a practical microservice application demonstrates that ServiceFridge allows data center to reduce its dynamic power by 25% with slight performance loss. It improves the mean response time by 25.2% and improves the 90th tail latency by 18.0% compared with existing schemes.},
booktitle = {Proceedings of the 48th International Conference on Parallel Processing},
articleno = {10},
numpages = {10},
location = {Kyoto, Japan},
series = {ICPP 2019}
}

@inproceedings{10.1145/3465480.3467838,
author = {Das, Prangshuman and Laigner, Rodrigo and Zhou, Yongluan},
title = {HawkEDA: A Tool for Quantifying Data Integrity Violations in Event-Driven Microservices},
year = {2021},
isbn = {9781450385558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465480.3467838},
doi = {10.1145/3465480.3467838},
abstract = {A microservice architecture advocates for subdividing an application into small and independent components, each communicating via well-defined APIs or asynchronous events, to allow for higher scalability, availability, and fault isolation. However, the implementation of substantial amount of data management logic at the application-tier and the existence of functional dependencies cutting across microservices create a great barrier for developers to reason about application safety and performance trade-offs.To fill this gap, this work presents HawkEDA, the first data management tool that allows practitioners to experiment their microservice applications with different real-world workloads to quantify the amount of data integrity anomalies. In our demonstration, we present a case study of a popular open-source event-driven microservice to showcase the interface through which developers specify application semantics and the flexibility of HawkEDA.},
booktitle = {Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems},
pages = {176–179},
numpages = {4},
keywords = {microservice, data integrity, event-driven architecture},
location = {Virtual Event, Italy},
series = {DEBS '21}
}

@inproceedings{10.5555/3374138.3374171,
author = {Bocciarelli, Paolo and D'Ambrogio, Andrea and Giglio, Andrea and Paglia, Emiliano},
title = {A Microservice-Based Approach for Fine-Grained Simulation in MSaaS Platforms},
year = {2019},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {M&amp;S as a Service (MSaaS) is an increasingly adopted paradigm that brings the benefits of service-oriented architectures and cloud computing into the M&amp;S field. The design and implementation of MSaaS platforms typically address the provision of coarse-grained M&amp;S services, which offer the user easy access and orchestration of M&amp;S components consisting of entire environments, applications and/or tools. This paper introduces an approach to the provision of fine-grained M&amp;S services, which are defined by use of a microservice-based architecture, according to which applications are developed as a suite of small-sized services. The proposed approach extends an already available MSaaS platform, named SOASim. The paper shows how the integration and mutual use of fine-grained and coarse-grained services (e.g., modeling services, transformation services, presentation services etc.) significantly enhance the benefits of SOASim. An example application to the microservice-based setup of a discrete event simulation is used to describe and discuss the proposed approach.},
booktitle = {Proceedings of the 2019 Summer Simulation Conference},
articleno = {33},
numpages = {12},
keywords = {DES, SaaS, microservices, MSaaS, cloud},
location = {Berlin, Germany},
series = {SummerSim '19}
}

@inproceedings{10.1145/3297280.3297400,
author = {Cardarelli, Mario and Iovino, Ludovico and Di Francesco, Paolo and Di Salle, Amleto and Malavolta, Ivano and Lago, Patricia},
title = {An Extensible Data-Driven Approach for Evaluating the Quality of Microservice Architectures},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297400},
doi = {10.1145/3297280.3297400},
abstract = {Microservice architecture (MSA) is defined as an architectural style where the software system is developed as a suite of small services, each running in its own process and communicating with lightweight mechanisms. The benefits of MSA are many, ranging from an increase in development productivity, to better business-IT alignment, agility, scalability, and technology flexibility. The high degree of microservices distribution and decoupling is, however, imposing a number of relevant challenges from an architectural perspective. In this context, measuring, controlling, and keeping a satisfactory level of quality of the system architecture is of paramount importance.In this paper we propose an approach for the specification, aggregation, and evaluation of software quality attributes for the architecture of microservice-based systems. The proposed approach allows developers to (i) produce architecture models of the system, either manually or automatically via recovering techniques, (ii) contribute to an ecosystem of well-specified and automatically-computable software quality attributes for MSAs, and (iii) continuously measure and evaluate the architecture of their systems by (re-)using the software quality attributes defined in the ecosystem. The approach is implemented by using Model-Driven Engineering techniques.The current implementation of the approach has been validated by assessing the maintainability of a third-party, publicly available benchmark system.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1225–1234},
numpages = {10},
keywords = {model-driven, software quality, microservices, architecture recovery},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3538969.3538986,
author = {Billawa, Priyanka and Bambhore Tukaram, Anusha and D\'{\i}az Ferreyra, Nicol\'{a}s E. and Stegh\"{o}fer, Jan-Philipp and Scandariato, Riccardo and Simhandl, Georg},
title = {SoK: Security of Microservice Applications: A Practitioners’ Perspective on Challenges and Best Practices},
year = {2022},
isbn = {9781450396707},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3538969.3538986},
doi = {10.1145/3538969.3538986},
abstract = {Cloud-based application deployment is becoming increasingly popular among businesses, thanks to the emergence of microservices. However, securing such architectures is a challenging task since traditional security concepts cannot be directly applied to microservice architectures due to their distributed nature. The situation is exacerbated by the scattered nature of guidelines and best practices advocated by practitioners and organizations in this field. In this research paper we aim to shay light over the current microservice security discussions hidden within Grey Literature (GL) sources. Particularly, we identify the challenges that arise when securing microservice architectures, as well as solutions recommended by practitioners to address these issues. For this, we conducted a systematic GL study on the challenges and best practices of microservice security present in the Internet with the goal of capturing relevant discussions in blogs, white papers, and standards. We collected 312 GL sources from which 57 were rigorously classified and analyzed. This analysis on the one hand validated past academic literature studies in the area of microservice security, but it also identified improvements to existing methodologies pointing towards future research directions.},
booktitle = {Proceedings of the 17th International Conference on Availability, Reliability and Security},
articleno = {9},
numpages = {10},
keywords = {security, grey literature, microservices, best practices, challenges},
location = {Vienna, Austria},
series = {ARES '22}
}

@inproceedings{10.1145/3234152.3234195,
author = {Eski, Sinan and Buzluca, Feza},
title = {An Automatic Extraction Approach: Transition to Microservices Architecture from Monolithic Application},
year = {2018},
isbn = {9781450364225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3234152.3234195},
doi = {10.1145/3234152.3234195},
abstract = {Microservice architecture has been introduced as a new alternative to the monolithic architecture. It has several benefits like scalability, reliability, increase in agility and productivity, resilience to failure, ease of deployment and maintenance, and decrease in time to market. Therefore, software companies have showed a tendency to transform architecture of their legacy applications from monoliths to microservice architecture. In this transformation process, software development teams face the challenge of migration of large applications to the new architecture, where understanding the current application and reusing existing code base are important. In this paper, we propose a new approach to transform existing applications into microservices using code repositories. We use evolutionary and static code coupling information, and the graph clustering methodology, in order to automatically extract microservices from monoliths. In experimental analysis, we investigate two software projects and our approach reach up to 89% of success rate by comparing extracted microservices with the actual results.},
booktitle = {Proceedings of the 19th International Conference on Agile Software Development: Companion},
articleno = {25},
numpages = {6},
keywords = {microservices, graph clustering, microservice transformation, software architecture},
location = {Porto, Portugal},
series = {XP '18}
}

@inproceedings{10.1145/3425269.3425270,
author = {Araujo, Elena A. and Esp\'{\i}ndola, \'{A}lvaro M. and Garcia, Vinicius Cardoso and Terra, Ricardo},
title = {Applying a Multi-Platform Architectural Conformance Solution in a Real-World Microservice-Based System},
year = {2020},
isbn = {9781450387545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425269.3425270},
doi = {10.1145/3425269.3425270},
abstract = {Microservice architectures are composed of a set of independent microservices that execute well-defined functionalities, allowing each one to be developed in different programming languages and data management technologies. The problem, however, is that such heterogeneity implies in a harder verification process of communication among microservices and the architectural designs of each microservice. Although the state-of-the-art provides several architectural conformance solutions, none formally restricts communications (e.g., over HTTP) between different systems. Even stable and industrial solutions---such as Kubernetes, Terraform, and Docker Compose---provide basic mechanisms to restrict communications between microservices. Thereupon, this paper proposes and evaluates a multi-platform architectural conformance solution for the microservice architecture. For this purpose, (i) we specify an architectural constraint language, called DCL+---adapted from the DCL (Dependency Constraint Language) language; (ii) we propose a multi-platform process that restricts the communication between the microservices and also verifies the architectural projects of each one of them; (iii) we develop DCL+check, a tool that implements the proposed solution; (iv) we apply our process in a medium-size real-world application composed of eleven microservices, developed in two different languages (JavaScript and Java). As result, we found 16 communication and 171 structural design violations. The communication violations occurred in general due to the lack of knowledge of the developers about the restrictions of communication among the modules of the orchestrator system and other microservices, as well as the evolution of two microservices.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {41–50},
numpages = {10},
location = {Natal, Brazil},
series = {SBCARS '20}
}

@inproceedings{10.1145/3167132.3167314,
author = {Benni, Benjamin and Mosser, S\'{e}bastien and Collet, Philippe and Riveill, Michel},
title = {Supporting Micro-Services Deployment in a Safer Way: A Static Analysis and Automated Rewriting Approach},
year = {2018},
isbn = {9781450351911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167132.3167314},
doi = {10.1145/3167132.3167314},
abstract = {The SOA ecosystem has drastically evolved since its childhood in the early 2000s. From monolithic services, micro-services now cooperate together in ultra-large scale systems. In this context, there is a tremendous need to deploy frequently new services, or new version of existing services. Container-based technologies (e.g., Docker) emerged recently to tool such deployments, promoting a black-box reuse mechanism to support off-the-shelf deployments. Unfortunately, from the service deployment point of view, such form of black-box reuse prevent to ensure what is really shipped inside the container with the service to deploy. In this paper, we propose a formalism to model and statically analyze service deployment artifacts based on state of the art deployment platforms. The static analysis mechanism leverages the hierarchy of deployment descriptors to verify a given deployment, as well as rewrite it to automatically fix common errors. The approach is validated through the automation of the guidelines provided by the user community associated to the reference Docker engine, and the analysis of 20,000 real deployment descriptors (hosted on GitHub).},
booktitle = {Proceedings of the 33rd Annual ACM Symposium on Applied Computing},
pages = {1706–1715},
numpages = {10},
keywords = {container, docker, microservice, static analysis},
location = {Pau, France},
series = {SAC '18}
}

@inproceedings{10.1145/2996890.2996908,
author = {Wang, Wei and Zhang, Jingxuan and Guo, Dong and Xiang, Qiao and Huang, Chenxi and Chang, Jinda and Zhang, Liqing},
title = {Towards an Emerging Cloudware Paradigm for Transparent Computing},
year = {2016},
isbn = {9781450346160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2996890.2996908},
doi = {10.1145/2996890.2996908},
abstract = {Transparent computing is an implementation of ubiquitous computing that is aimed at providing active services for users. In transparent computing, the execution (computation) of computer instructions and data is temporally and spatially separated from their storage. Cloud computing solves the issue of data cloudlization, while transparent computing solves the one of software cloudlization. This paper define the concept of Cloudware, and discusses how to deploy Cloudware in cloud environment efficiently. Based on a loosely coupled von Neumann computing model (also called Cygnus Model), we proposes a new platform to construct the PaaS platform which can directly deploy software on the cloud without any modification, while achieving a new model by the browser services, and we call it transparent computing 2.0. By using micro-service architecture, we can achieve such characteristics as good performance, scalable deployment, faults tolerance and flexible configuration. Finally, we presents a Cloudware PaaS platform prototype, called CloudwareHub, and demonstrates the promising of the transparent computing 2.0 with the support of Cloudware technology.},
booktitle = {Proceedings of the 9th International Conference on Utility and Cloud Computing},
pages = {43–48},
numpages = {6},
keywords = {cloudware, cloud computing, transparent computing, service},
location = {Shanghai, China},
series = {UCC '16}
}

@inproceedings{10.1109/MSR.2019.00051,
author = {Bandeira, Alan and Medeiros, Carlos Alberto and Paixao, Matheus and Maia, Paulo Henrique},
title = {We Need to Talk about Microservices: An Analysis from the Discussions on StackOverflow},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2019.00051},
doi = {10.1109/MSR.2019.00051},
abstract = {Microservices are a new and rapidly growing architectural model aimed at developing highly scalable software solutions based on independently deployable and evolvable components. Due to its novelty, microservice-related discussions are increasing in Q&amp;A websites, such as StackOverflow (SO). In order to understand what is being discussed by the microservice community, this work has applied mining techniques and topic modelling to a manually-curated dataset of 1,043 microservice-related posts from StackOverflow. As a result, we found that 13.68% of microservice technical posts on SO discuss a single technology: Netflix Eureka. Moreover, buzzwords in the microservice ecosystem, e.g., blue/green deployment, were not identified as relevant subjects of discussion on SO. Finally, we show how a high discussion rate on SO may not reflect the popularity of a certain subject within the microservice community.},
booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories},
pages = {255–259},
numpages = {5},
keywords = {microservice, StackOverflow, topic modelling},
location = {Montreal, Quebec, Canada},
series = {MSR '19}
}

@inproceedings{10.1145/3123779.3123809,
author = {Pol\'{a}k, Marek and Holubov\'{a}, Irena},
title = {Information System Evolution Management: A Complex Evaluation},
year = {2017},
isbn = {9781450348430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123779.3123809},
doi = {10.1145/3123779.3123809},
abstract = {In our previous papers we have focused on problems of model and/or information system evolution. We have dealt with popular technologies and languages for data storage and data management, such as XML, SQL, XPath, REST, BPMN, etc. In this paper we sum up our contributions and present a complex example of evolution process of an information system. We model complex situations that, starting from a single point, influence the whole system.Our solution, however, brings benefits not only for a typical system with the well-known architecture "presentation layer -- business layer -- database layer", but also for the micro-service architecture that becomes more and more popular these days. In this paradigm every service is specialized, it manages a specific logical part of the system, and it communicates with other services mainly via HTTP or (web) sockets. This architecture brings many advantages especially to system scalability, performance, and resource management. On the other hand, separation of the system to micro-services brings drawbacks, such as more demanding change management and version compatibility. For example, a change of the message structure in one part of the system can influence all related services, integration tests are more complex and must detect more edge cases that in case of monolithic systems, etc. A mechanism that can analyze the changes, propagate them, and/or at least inform the developer about possible inconsistency can reduce time needed for updates and troubleshooting.},
booktitle = {Proceedings of the Fifth European Conference on the Engineering of Computer-Based Systems},
articleno = {18},
numpages = {4},
keywords = {information system maintenance, change propagation, evolution management},
location = {Larnaca, Cyprus},
series = {ECBS '17}
}

@inproceedings{10.1145/3382025.3414981,
author = {Setyautami, Maya R. A. and Fadhlillah, Hafiyyan S. and Adianto, Daya and Affan, Ichlasul and Azurat, Ade},
title = {Variability Management: Re-Engineering Microservices with Delta-Oriented Software Product Lines},
year = {2020},
isbn = {9781450375696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3382025.3414981},
doi = {10.1145/3382025.3414981},
abstract = {Combining microservices and software product line engineering (SPLE) is a challenge in variability management. This paper proposes a solution to that challenge by re-engineering existing webshop systems into a product line application. We first perform feature identification to analyze the features of subject systems. We introduce a mechanism that models the variability and designs a software product line architecture based on existing features. We use a UML diagram with the UML-DOP profile to abstract microservice variability in SPLE. Then, a transformation into a product line application is conducted to generate running applications based on selected features. We utilize a preliminary framework of microservice variability based on delta-oriented programming.},
booktitle = {Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A},
articleno = {23},
numpages = {6},
keywords = {microservice, re-engineering, UML profile, software product line engineering, delta-oriented programming},
location = {Montreal, Quebec, Canada},
series = {SPLC '20}
}

@inproceedings{10.1109/ECASE.2019.00013,
author = {Yuan, Eric},
title = {Architecture Interoperability and Repeatability with Microservices: An Industry Perspective},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ECASE.2019.00013},
doi = {10.1109/ECASE.2019.00013},
abstract = {Microservices, along with supporting technologies such as containers, have become a prevalent architecture approach for today's software systems, especially in enterprise environments. They represent the latest evolutionary step in the decades-old journey towards service- and component-based software architectures. Along with virtualization technologies, microservices have enabled the loose-coupling of both service interfaces (message passing) and service integration (form and fit). This paper attempts to explore the impact of microservices on software architecture interoperability and repeatability, based on our experiences in developing two microservice-based systems. Our central thesis is that, if we view software architecture as a set of principal design decisions, the microservices approach enable us to more elegantly separate these decisions from non-architectural, domain-specific ones, and thus make these decisions more interoperable, reusable, and repeatable across disparate problem domains. We therefore propose that a microservices based reference architecture (RA) and reference implementation (RI) be created for the community-wide infrastructure for software engineering and software architecture research, along with a set of detailed considerations.},
booktitle = {Proceedings of the 2nd International Workshop on Establishing a Community-Wide Infrastructure for Architecture-Based Software Engineering},
pages = {26–33},
numpages = {8},
keywords = {microservice, cloud computing, DevOps, software architecture},
location = {Montreal, Quebec, Canada},
series = {ECASE '19}
}

@inproceedings{10.1145/3489525.3511677,
author = {Baluta, Alexandru and Mukherjee, Joydeep and Litoiu, Marin},
title = {Machine Learning Based Interference Modelling in Cloud-Native Applications},
year = {2022},
isbn = {9781450391436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489525.3511677},
doi = {10.1145/3489525.3511677},
abstract = {Cloud-native applications are often composed of lightweight containers and conform to the microservice architecture. Cloud providers offer platforms for container hosting and orchestration. These platforms reduce the level of support required from the application owner as operational tasks are delegated to the platform. Furthermore, containers belonging to different applications can be co-located on the same virtual machine to utilize resources more efficiently. Given that there are underlying shared resources and consequently potential performance interference, predicting the level of interference before deciding to share virtual machines can avoid undesirable performance deterioration. We propose a lightweight performance interference modelling technique for cloud-native microservices. The technique constructs ML models for response time prediction and can dynamically account for changing runtime conditions through the use of a sliding window method. We evaluate our technique against realistic microservices on AWS EC2. Our technique outperforms baseline and competing techniques in MAPE by at least 1.45% and at most 92.04%.},
booktitle = {Proceedings of the 2022 ACM/SPEC on International Conference on Performance Engineering},
pages = {125–132},
numpages = {8},
keywords = {cloud computing, machine learning, interference, microservice},
location = {Beijing, China},
series = {ICPE '22}
}

@inproceedings{10.1145/3485983.3494867,
author = {Cao, Lianjie and Sharma, Puneet},
title = {Co-Locating Containerized Workload Using Service Mesh Telemetry},
year = {2021},
isbn = {9781450390989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485983.3494867},
doi = {10.1145/3485983.3494867},
abstract = {The cloud-native architecture and container-based technologies are revolutionizing how online services and applications are designed, developed, and managed by offering better elasticity and flexibility to developers and operators. However, the increasing adoption of microservice and serverless designs makes application workload more decomposed and transient at a larger scale. Most existing container orchestration systems still manage application workload based on simple system-level resource usage and policies manually created by operators, leading to ineffective application-agnostic scheduling and extra management burden for operators.In this work, we focus on workload placement for containerized applications and services and argue for the integration of application-level telemetry for profiling application status and co-locating application workload. To avoid extra performance overhead and modifications to existing applications, we propose to use the telemetry collected by service mesh to model the application communication patterns with a graph-based representation. By applying a graph partitioning algorithm, we create co-location groups for application workload that minimize cross-group communication traffic to improve the overall application performance, i.e., response time. Our preliminary experiments with a realistic online e-commerce application show that our solution can reduce the average response time by up to 58% compared to the default Kubernetes scheduler.},
booktitle = {Proceedings of the 17th International Conference on Emerging Networking EXperiments and Technologies},
pages = {168–174},
numpages = {7},
keywords = {service mesh, cloud computing, microservice},
location = {Virtual Event, Germany},
series = {CoNEXT '21}
}

@inproceedings{10.1145/3403746.3403915,
author = {Wang, YingQiang and Han, Wei and Nian, ZhaoHua},
title = {Design of Satellite Ground Management System Based on Microservices},
year = {2020},
isbn = {9781450375528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3403746.3403915},
doi = {10.1145/3403746.3403915},
abstract = {With the rapid development and construction of domestic remote sensing satellite ground systems, the traditional architecture is no longer able to meet the needs of future development. At the same time, technicians are also spending a lot of time when upgrading and maintaining. Widespread application of microservice architecture in recent years has provided a technological approach that can meet the requirements of rapid development, iterative upgrades and flexible deployment. This paper designs a satellite ground management system based on the microservice architecture, focusing on the overall architecture design and application system design based on this new architecture. The results show that the satellite ground management system based on the microservice architecture can have good availability and reliability, reducing the coupling degree of the system, can also meet the new business requirements of high availability, high concurrency, high fault tolerance, and good scalability.},
booktitle = {Proceedings of the 2020 3rd International Conference on Computer Science and Software Engineering},
pages = {119–123},
numpages = {5},
keywords = {Microservice architecture, Satellite ground management system, Docker},
location = {Beijing, China},
series = {CSSE 2020}
}

@inproceedings{10.1145/3338906.3341178,
author = {Stallenberg, Dimitri Michel and Panichella, Annibale},
title = {JCOMIX: A Search-Based Tool to Detect XML Injection Vulnerabilities in Web Applications},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3341178},
doi = {10.1145/3338906.3341178},
abstract = {Input sanitization and validation of user inputs are well-established protection mechanisms for microservice architectures against XML injection attacks (XMLi). The effectiveness of the protection mechanisms strongly depends on the quality of the sanitization and validation rule sets (e.g., regular expressions) and, therefore, security analysts have to test them thoroughly. In this demo, we introduce JCOMIX, a penetration testing tool that generates XMLi attacks (test cases) exposing XML vulnerabilities in front-end web applications. JCOMIX implements various search algorithms, including random search (traditional fuzzing), genetic algorithms (GAs), and the more recent co-operative, co-evolutionary algorithm designed explicitly for the XMLi testing (COMIX). We also show the results of an empirical study showing the effectiveness of JCOMIX in testing an open-source front-end web application.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1090–1094},
numpages = {5},
keywords = {Search-based Software Engineering, XML injection, Security Testing, Test Case Generation},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/3463274.3463334,
author = {Wolfart, Daniele and Assun\c{c}\~{a}o, Wesley K. G. and da Silva, Ivonei F. and Domingos, Diogo C. P. and Schmeing, Ederson and Villaca, Guilherme L. Donin and Paza, Diogo do N.},
title = {Modernizing Legacy Systems with Microservices: A Roadmap},
year = {2021},
isbn = {9781450390538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463274.3463334},
doi = {10.1145/3463274.3463334},
abstract = {Legacy systems are long-lived applications, with obsolete technology and degraded architecture. These systems hamper digital transformation and innovation, and require a great amount of resources for maintenance. The modernization of monolithic legacy systems is a strategy to promote better evolution and maintenance, taking advantage of new technologies such as microservices. Microservice architectural style is a paradigm to develop systems as a suite of small and autonomous services, communicating through a lightweight protocol. However, the migration of legacy systems to microservices is complex. Although we can find several studies on this topic, they usually focus on specific activities, e.g., the identification of the microservice boundaries in the legacy code. Also, existing pieces of work do not cover real-world scenarios, since they do not take into account organizational, operational, and technical aspects. To overcome this limitation, in this paper we present a roadmap for modernizing monolithic legacy systems with microservices. The roadmap is distilled from the existing body of knowledge, describing common activities and input/output information. The proposed roadmap is composed of eight activities, grouped in four phases, namely initiation, planning, execution, and monitoring. The main contributions are: (i) serve as a basis for practitioners to plan, execute, and monitor the modernization process; (ii) be a reference for researchers to design new studies; and (iii) motivate tool builders to deal with existing needs.},
booktitle = {Evaluation and Assessment in Software Engineering},
pages = {149–159},
numpages = {11},
keywords = {Software Migration, Cloud Computing, Software Evolution},
location = {Trondheim, Norway},
series = {EASE 2021}
}

@inproceedings{10.1145/2949550.2949655,
author = {Scarborough, Walter and Arnold, Carrie and Dahan, Maytal},
title = {Case Study: Microservice Evolution and Software Lifecycle of the XSEDE User Portal API},
year = {2016},
isbn = {9781450347556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2949550.2949655},
doi = {10.1145/2949550.2949655},
abstract = {The XSEDE User Portal (XUP) [1] is a web interface providing a set of user specific XSEDE services and documentation to a diverse audience. The XUP architecture started out depending on monolithic services provided by large Java libraries, but continues to evolve to use an application programming interface (API) [2] powered by a set of microservices [3]. The goal is to have the XUP API provide development and deployment environments that are agile, sustainable, and capable of handling feature changes. In making this transition, we have developed guidelines for API services that balance complexity and reuse needs with flexibility requirements. In doing so, we have also created our own set of best practices on how to convert to using microservices. In this paper we will use the XSEDE User Portal API development as a case study to explain our rationale, approach, and experiences in working with microservices in a real production environment to provide better and more reliable science services for end users.},
booktitle = {Proceedings of the XSEDE16 Conference on Diversity, Big Data, and Science at Scale},
articleno = {47},
numpages = {5},
keywords = {Microservices, API, XSEDE User Portal},
location = {Miami, USA},
series = {XSEDE16}
}

@inproceedings{10.1145/3524304.3524325,
author = {Cao, Lingli and Zhang, Cheng},
title = {Implementation of Domain-Oriented Microservices Decomposition Based on Node-Attributed Network},
year = {2022},
isbn = {9781450385770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524304.3524325},
doi = {10.1145/3524304.3524325},
abstract = {The features of microservices, such as scalability and maintainability, have attracted the industry to migrate monolithic projects to microservices. However, how to decompose microservices during migration is a tricky problem. At present, microservices decomposition mainly relies on architects or domain experts, which is more subjective and time-consuming. Followed by semi-automated or automated microservice decomposition, such methods produce coarse-grained results affected by different system characteristics, which cannot make desired decomposition according to the migration requirements of domains. Therefore, this paper proposes a domain-oriented fine-grained microservices decomposition resolution scheme. It uses dynamic and static analysis to obtain the invocation relationships and invocation times between entity methods and the response time of entity methods to represent three main system characteristics concerned during the migration: function, inter-service communications, and performance. And express the above information of monolith by the node-attributed network. Then it uses the community detection algorithm and the proposed similar hierarchical clustering algorithm to complete objective and effective decomposition. Finally, the rationality and feasibility of the proposed approach are verified using the JPetStore case.},
booktitle = {2022 11th International Conference on Software and Computer Applications},
pages = {136–142},
numpages = {7},
keywords = {Dynamic analysis, Static analysis, Domain, Microservices Decomposition, Node-attributed Network},
location = {Melaka, Malaysia},
series = {ICSCA 2022}
}

@inproceedings{10.1145/3424771.3424812,
author = {Tighilt, Rafik and Abdellatif, Manel and Moha, Naouel and Mili, Hafedh and Boussaidi, Ghizlane El and Privat, Jean and Gu\'{e}h\'{e}neuc, Yann-Ga\"{e}l},
title = {On the Study of Microservices Antipatterns: A Catalog Proposal},
year = {2020},
isbn = {9781450377690},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3424771.3424812},
doi = {10.1145/3424771.3424812},
abstract = {Microservice architecture has become popular in the last few years as it allows the development of independent, highly reusable, and fine grained services. However, a lack of understanding of its core concepts and the absence of a ground-truth lead to design and implementation decisions, which might be applied often and introduce poorly designed solutions, called antipatterns. The definition of microservice antipatterns is essential for improving the design, maintenance, and evolution of microservice-based systems. Moreover, the few existing specifications and definitions of microservice antipatterns are scattered in the literature. Consequently, we conducted a systematic literature review of 27 papers related to microservices and analyzed 67 open-source microservice-based systems. Based on our analysis, we report in this paper 16 microservice antipatterns. We concisely describe these antipatterns, how they are implemented, and suggest refactoring solutions to remove them.},
booktitle = {Proceedings of the European Conference on Pattern Languages of Programs 2020},
articleno = {34},
numpages = {13},
keywords = {Microservices, architecture, antipatterns},
location = {Virtual Event, Germany},
series = {EuroPLoP '20}
}

@inproceedings{10.1145/3483899.3483904,
author = {Colanzi, Thelma and Amaral, Aline and Assun\c{c}\~{a}o, Wesley and Zavadski, Arthur and Tanno, Douglas and Garcia, Alessandro and Lucena, Carlos},
title = {Are We Speaking the Industry Language? The Practice and Literature of Modernizing Legacy Systems with Microservices},
year = {2021},
isbn = {9781450384193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3483899.3483904},
doi = {10.1145/3483899.3483904},
abstract = {Microservice architecture has gained much attention in the last few years in both industry and academia. Microservice is an architectural style that enables developing systems as a suite of small loosely coupled, and autonomous (micro)services that encapsulate business capabilities and communicate with each other using language-agnostic APIs. Despite the microservice adoption for modernizing legacy systems, few studies investigate how microservices are used in practice. Furthermore, the literature still scarce on presenting studies on why and how the modernization is conducted in practice in comparison to existing literature on the subject. Thus, our goal is to investigate if industry and academy are speaking the same language concerning the modernization of legacy systems with microservices, by means of a rigorous study on the use of microservices in the industry. For doing so, we design a survey to understand the state of practice from the perspective of a modernization process roadmap derived from the literature. In this paper, we report the results of a survey with 56 software companies, from which 35 (63.6%) adopt the microservice architecture in their legacy systems. Results pointed out the most expected benefits that drive the migration to microservices are easier software maintenance, better scalability, ease of deployment, and technology flexibility. Besides, we verified, based on a set of activities defined in the modernization process, that the practitioners are performing their migration process according to the best literature practices.},
booktitle = {15th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {61–70},
numpages = {10},
keywords = {Software Migration, Software Re-engineering, Microservices},
location = {Joinville, Brazil},
series = {SBCARS '21}
}

@inproceedings{10.1145/3147234.3148093,
author = {Shadija, Dharmendra and Rezai, Mo and Hill, Richard},
title = {Microservices: Granularity vs. Performance},
year = {2017},
isbn = {9781450351959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147234.3148093},
doi = {10.1145/3147234.3148093},
abstract = {Microservice Architectures (MA) have the potential to increase the agility of software development. In an era where businesses require software applications to evolve to support emerging software requirements, particularly for Internet of Things (IoT) applications, we examine the issue of microservice granularity and explore its effect upon application latency. Two approaches to microservice deployment are simulated; the first with microservices in a single container, and the second with microservices partitioned across separate containers. We observed a negligible increase in service latency for the multiple container deployment over a single container.},
booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {215–220},
numpages = {6},
keywords = {internet of things, performance, microservice architecture, software engineering},
location = {Austin, Texas, USA},
series = {UCC '17 Companion}
}

@inproceedings{10.1145/3357141.3357603,
author = {Azevedo, Leonardo Guerreiro and Ferreira, Rodrigo da Silva and Silva, Viviane Torres da and de Bayser, Maximillien and Soares, Elton F. de S. and Thiago, Raphael Melo},
title = {Geological Data Access on a Polyglot Database Using a Service Architecture},
year = {2019},
isbn = {9781450376372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357141.3357603},
doi = {10.1145/3357141.3357603},
abstract = {In a microservice architecture, solutions are built through collaboration of distributed services across networks. In the Oil &amp; Gas industry, in exploration and production phases, organization units executes different services over several diverse datasets. Geological data usually is in high volume and encompasses different kinds of data objects, with diverse structure and nature, such as seismic data, seismic horizon and well data. Querying, processing, and composing geological data presents strong demands for domain knowledge representation and reasoning, and tailored processing techniques. This work presents an application of microservices architecture and polyglot persistence technologies to handle the requirements of geological data in the Oil &amp; Gas domain. This architecture allows parties communicate in a light way, while encapsulating processing and data access to a geological database and to a knowledge base. It also works as a common layer, composing parties' services results for data consumption by clients. We exemplify the proposal by presenting and analyzing its use in a real scenario which includes some of the implemented queries in a developed system to support geological data analysis. We present the main characteristics of the system and highlights lessons learned in its development.},
booktitle = {Proceedings of the XIII Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {103–112},
numpages = {10},
keywords = {geological data, microservice architecture, reasoning, polyglot persistence},
location = {Salvador, Brazil},
series = {SBCARS '19}
}

@inproceedings{10.1109/CESSER-IP.2019.00012,
author = {Carvalho, Luiz and Garcia, Alessandro and Assun\c{c}\~{a}o, Wesley K. G. and de Mello, Rafael and de Lima, Maria Julia},
title = {Analysis of the Criteria Adopted in Industry to Extract Microservices},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CESSER-IP.2019.00012},
doi = {10.1109/CESSER-IP.2019.00012},
abstract = {A microservice architecture is expected to provide a better modularization and management of small and autonomous services. Other expected benefits include increased availability and time to market. There is a growing interest of both industry and academia on streamlining the migration of existing systems to a microservice architecture. However, the success of this migration is largely dependent on the use of appropriate criteria for extracting microservices from a code base. Recent studies indicate the selection and decomposition of microservices represent the main challenge along the migration. Academic techniques tend to support the extraction of microservices with either one or two conventional criteria, namely coupling and cohesion. There is limited knowledge on the criteria actually considered as useful by practitioners. Thus, we have performed an exploratory online survey with 15 specialists experienced on migrating systems to a microservices architecture. In particular, we question the relative usefulness of seven possible criteria for supporting decision-making along microservice extraction. The participants were also questioned about tools they have used, their limitations, and whether the decisions on extracted microservices were considered unsuccessful. Overall, the survey results suggest academic techniques do not totally satisfy the needs of practitioners. Practitioners often need to consider simultaneously at least four dominant criteria as well as their trade-offs to support their decisions. Most practitioners consider existing tooling support insufficient or even irrelevant to support their microservice extraction decisions.},
booktitle = {Proceedings of the Joint 7th International Workshop on Conducting Empirical Studies in Industry and 6th International Workshop on Software Engineering Research and Industrial Practice},
pages = {22–29},
numpages = {8},
keywords = {industry, extraction, survey, microservices, reengineering},
location = {Montreal, Quebec, Canada},
series = {CESSER-IP '19}
}

@article{10.1145/3392350.3392351,
author = {Walker, Andrew and Cerny, Tomas},
title = {On Cloud Computing Infrastructure for Existing Code-Clone Detection Algorithms},
year = {2020},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {1559-6915},
url = {https://doi.org/10.1145/3392350.3392351},
doi = {10.1145/3392350.3392351},
abstract = {Microservice Architecture (MSA) is becoming a design standard for modern cloud-based software systems. However, even though cloud-based applications have been thoroughly explored with regards to networking, scalability, and decomposition of existing monolithic applications into MSA based applications, not much research has been done showing the viability of MSA in new problem domains. In this paper, we explore the application of MSA to the code-clone detection problem domain to identify any improvements that can be made over existing local code-clone detection applications. A fragment of source code that is identical or similar to another is a code-clone. Code-clones make it difficult to maintain applications as they create multiple points within the code that bugs must be fixed, new rules enforced, or design decisions imposed. As applications grow larger and larger, the pervasiveness of code-clones likewise grows. To face the code-clone related issues, many tools and algorithms have been proposed to find and document code-clones within an application. In this paper, we show that many improvements can be made by utilizing emerging cloud-based technologies.},
journal = {SIGAPP Appl. Comput. Rev.},
month = {apr},
pages = {5–14},
numpages = {10},
keywords = {code clone, scalable code clone detection, clone detection, software as a service, microservices, cloud computing}
}

@article{10.5555/3447080.3447091,
author = {Border, Charles},
title = {Development of a Configuration Management Course for Computing Operations Students},
year = {2020},
issue_date = {October 2020},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {36},
number = {3},
issn = {1937-4771},
abstract = {The Operations side of deploying a modern computing application necessarily involves multiple groups working in concert to develop the application and the server side configuration that will support that application. This paper reports on efforts to develop a course that encourages students to dig into issues related to configuration management, security policy development, application auditing, business control issues, and most importantly, team work. While the course is entitled "Configuration Management" it is much more about students creating a process for secure iterative application deployment that borrows extensively from the DevOps movement.Ansible, our chosen configuration management tool, is relatively easy to work with at the level of complexity that can be reached in an undergraduate class. What made this class different was the attempt made to create a process that would more closely mimic the Operations side of a DevOps workflow. Initial results from the class were encouraging and many lessons were learned.},
journal = {J. Comput. Sci. Coll.},
month = {oct},
pages = {89–101},
numpages = {13}
}

@inproceedings{10.1145/3243734.3243862,
author = {Li, Hongda and Hu, Hongxin and Gu, Guofei and Ahn, Gail-Joon and Zhang, Fuqiang},
title = {VNIDS: Towards Elastic Security with Safe and Efficient Virtualization of Network Intrusion Detection Systems},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243862},
doi = {10.1145/3243734.3243862},
abstract = {Traditional Network Intrusion Detection Systems (NIDSes) are generally implemented on vendor proprietary appliances or middleboxes with poor versatility and flexibility. Emerging Network Function Virtualization (NFV) and Software-Defined Networking (SDN) technologies can virtualize NIDSes and elastically scale them to deal with attack traffic variations. However, such an elasticity feature must not come at the cost of decreased detection effectiveness and expensive provisioning. In this paper, we propose an innovative NIDS architecture, vNIDS, to enable safe and efficient virtualization of NIDSes. vNIDS addresses two key challenges with respect to effective intrusion detection and non-monolithic NIDS provisioning in virtualizing NIDSes. The former challenge is addressed by detection state sharing while minimizing the sharing overhead in virtualized environments. In particular, static program analysis is employed to determine which detection states need to be shared. vNIDS addresses the latter challenge by provisioning virtual NIDSes as microservices and employing program slicing to partition the detection logic programs so that they can be executed by each microservice separately. We implement a prototype of vNIDS to demonstrate the feasibility of our approach. Our evaluation results show that vNIDS could offer both effective intrusion detection and efficient provisioning for NIDS virtualization.},
booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
pages = {17–34},
numpages = {18},
keywords = {software-defined networking, network function virtualization, network intrusion detection systems},
location = {Toronto, Canada},
series = {CCS '18}
}

@inproceedings{10.1145/3241403.3241429,
author = {M\'{a}rquez, Gast\'{o}n and Villegas, M\'{o}nica M. and Astudillo, Hern\'{a}n},
title = {A Pattern Language for Scalable Microservices-Based Systems},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241429},
doi = {10.1145/3241403.3241429},
abstract = {Microservices are an emerging distributed architectural style to build highly scalable Web systems. Many design patterns have been proposed for microservices, and some of them for scalability, but this growing corpus has not yet been organized as a coherent, easy-to-use pattern language. This article builds on previous work that identified existing patterns for microservice-based systems, selects those related to scalability, and organizes them in three categories (load-balancing, decomposition, and grouping) corresponding to the three well-known scalability dimensions (also called X-, Y- and Z-axis). The pattern language use is illustrated with a case study of documenting the architecture of a real-time bus position capturing application. This principled pattern language yields a solid basis for organizing current and future patterns that address scalability of microservice-based systems.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {24},
numpages = {7},
keywords = {scalability, pattern language, microservices, software architecture},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3368235.3368847,
author = {Abdul Majeed, Ayesha and Kilpatrick, Peter and Spence, Ivor and Varghese, Blesson},
title = {Performance Estimation of Container-Based Cloud-to-Fog Offloading},
year = {2019},
isbn = {9781450370448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368235.3368847},
doi = {10.1145/3368235.3368847},
abstract = {Fog computing offloads latency critical services of a Cloud application onto resources located at the edge of the network that are in close proximity to end-user devices. The research in this paper is motivated towards characterising and estimating the time taken to offload a service using containers, which is investigated in the context of the 'Save and Load' container migration technique. To this end, the research addresses questions such as whether fog offloading can be accurately modelled and which system and network related parameters influence offloading. These are addressed by exploring a catalogue of 21 different metrics both at the system and process levels that is used as input to four estimation techniques using a collective model and individual models to predict the time taken for offloading. The study is pursued by collecting over 1.1 million data points and the preliminary results indicate that offloading can be modelled accurately.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
pages = {151–156},
numpages = {6},
keywords = {containers, fog computing, edge computing, offloading},
location = {Auckland, New Zealand},
series = {UCC '19 Companion}
}

@inproceedings{10.1145/3472883.3487005,
author = {Meiklejohn, Christopher S. and Estrada, Andrea and Song, Yiwen and Miller, Heather and Padhye, Rohan},
title = {Service-Level Fault Injection Testing},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3487005},
doi = {10.1145/3472883.3487005},
abstract = {Companies today increasingly rely on microservice architectures to deliver service for their large-scale mobile or web applications. However, not all developers working on these applications are distributed systems engineers and therefore do not anticipate partial failure: where one or more of the dependencies of their service might be unavailable once deployed into production. Therefore, it is paramount that these issues be raised early and often, ideally in a testing environment or before the code ships to production.In this paper, we present an approach called service-level fault injection testing and a prototype implementation called Filibuster, that can be used to systematically identify resilience issues early in the development of microservice applications. Filibuster combines static analysis and concolicstyle execution with a novel dynamic reduction algorithm to extend existing functional test suites to cover failure scenarios with minimal developer effort. To demonstrate the applicability of our tool, we present a corpus of 4 real-world industrial microservice applications containing bugs. These applications and bugs are taken from publicly available information of chaos engineering experiments run by large companies in production. We then demonstrate how all of these chaos experiments could have been run during development instead, and the bugs they discovered detected long before they ended up in production.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {388–402},
numpages = {15},
keywords = {verification, fault tolerance, fault injection},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@inproceedings{10.1145/3241403.3241426,
author = {Plakidas, Konstantinos and Schall, Daniel and Zdun, Uwe},
title = {Model-Based Support for Decision-Making in Architecture Evolution of Complex Software Systems},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241426},
doi = {10.1145/3241403.3241426},
abstract = {Design decision support for software architects in complex industrial software systems, such as software ecosystems and systems-of-systems, which feature extensive reuse of third-party solutions and a variety of deployment options, is still an open challenge. We describe three industrial use cases involving considerable re-architecting, where on-premises solutions were migrated to a cloud-based IoT platforms. Based on these use cases, we analyse the challenges and derive requirements for an architecture knowledge model supporting this process. The presented methodology builds upon existing approaches and proposes a model for the description of extant software applications and the management of domain knowledge. We demonstrate its use to support the evolution and/or composition of software applications in a migration scenario in a systematic and traceable manner.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {21},
numpages = {7},
keywords = {software migration, systems-of-systems composition, software architecture evolution, model-based decision support, software variability management},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3011141.3011179,
author = {de Camargo, Andr\'{e} and Salvadori, Ivan and Mello, Ronaldo dos Santos and Siqueira, Frank},
title = {An Architecture to Automate Performance Tests on Microservices},
year = {2016},
isbn = {9781450348072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011141.3011179},
doi = {10.1145/3011141.3011179},
abstract = {The microservices architecture provides a new approach to develop applications. As opposed to monolithic applications, in which the application comprises a single software artifact, an application based on the microservices architecture is composed by a set of services, each one designed to perform a single and well-defined task. These services allow the development team to decouple several parts of the application using different frameworks, languages and hardware for each part of the system. One of the drawbacks for adopting the microservices architecture to develop applications is testability. In a single application test boundaries can be more easily established and tend to be more stable as the application evolves, while with microservices we can have a set of hundreds of services that operate together and are prone to change more rapidly. Each one of these services needs to be tested and updated as the service changes. In addition, the different characteristics of these services such as languages, frameworks or the used infrastructure have to be considered in the testing phase. Performance tests are applied to assure that a particular software complies with a set of non-functional requirements such as throughput and response time. These metrics are important to ensure that business constraints are respected and to help finding performance bottlenecks. In this paper, we present a new approach to allow the performance tests to be executed in an automated way, with each microservice providing a test specification that is used to perform tests. Along with the architecture, we also provide a framework that implements some key concepts of this architecture. This framework is available as an open source project1.},
booktitle = {Proceedings of the 18th International Conference on Information Integration and Web-Based Applications and Services},
pages = {422–429},
numpages = {8},
keywords = {microservices, performance test, test automation},
location = {Singapore, Singapore},
series = {iiWAS '16}
}

@inproceedings{10.1145/3465480.3466919,
author = {Laigner, Rodrigo and Zhou, Yongluan and Salles, Marcos Antonio Vaz},
title = {A Distributed Database System for Event-Based Microservices},
year = {2021},
isbn = {9781450385558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465480.3466919},
doi = {10.1145/3465480.3466919},
abstract = {Microservice architectures are an emerging industrial approach to build large scale and event-based systems. In this architectural style, an application is functionally partitioned into several small and autonomous building blocks, so-called microservices, communicating and exchanging data with each other via events.By pursuing a model where fault isolation is enforced at microservice level, each microservice manages their own database, thus database systems are not shared across microservices. Developers end up encoding substantial data management logic in the application-tier and encountering a series of challenges on enforcing data integrity and maintaining data consistency across microservices.In this vision paper, we argue that there is a need to rethink how database systems can better support microservices and relieve the burden of handling complex data management tasks faced by programmers. We envision the design and research opportunities for a novel distributed database management system targeted at event-driven microservices.},
booktitle = {Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems},
pages = {25–30},
numpages = {6},
keywords = {database system, microservices, event-driven architecture},
location = {Virtual Event, Italy},
series = {DEBS '21}
}

@inproceedings{10.1145/3123779.3123804,
author = {Haselb\"{o}ck, Stefan and Weinreich, Rainer and Buchgeher, Georg},
title = {Decision Guidance Models for Microservices: Service Discovery and Fault Tolerance},
year = {2017},
isbn = {9781450348430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123779.3123804},
doi = {10.1145/3123779.3123804},
abstract = {Introducing a microservice system is a challenging task and requires the exploration and documentation of several related areas of design. Exploration and documentation of software architecture design is supported by decision guidance models in software architecture. In this paper, we present such guidance models for several microservice system design areas, including service discovery and fault tolerance. The presented models have been created based on existing microservice literature and have been validated and refined in design workshops with business partners as part of a technical action research (TAR) study.},
booktitle = {Proceedings of the Fifth European Conference on the Engineering of Computer-Based Systems},
articleno = {4},
numpages = {10},
keywords = {design decisions, microservices, software architecture, decision guidance models, technical action research (TAR)},
location = {Larnaca, Cyprus},
series = {ECBS '17}
}

@inproceedings{10.1145/3308560.3316509,
author = {W. Collier, Rem and O'Neill, Eoin and Lillis, David and O'Hare, Gregory},
title = {MAMS: Multi-Agent MicroServices✱},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3316509},
doi = {10.1145/3308560.3316509},
abstract = {This paper explores the intersection between microservices and Multi-Agent Systems (MAS), introducing the notion of a new approach to building MAS known as Multi-Agent MicroServices (MAMS). Our approach is illustrated through a worked example of a Vickrey Auction implemented as a microservice.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {655–662},
numpages = {8},
keywords = {text tagging, ACM proceedings},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3147213.3147229,
author = {Torkura, Kennedy A. and Sukmana, Muhammad I.H. and Meinel, Christoph},
title = {Integrating Continuous Security Assessments in Microservices and Cloud Native Applications},
year = {2017},
isbn = {9781450351492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147213.3147229},
doi = {10.1145/3147213.3147229},
abstract = {Cloud Native Applications (CNA) consists of multiple collaborating microservice instances working together towards common goals. These microservices leverage the underlying cloud infrastructure to enable several properties such as scalability and resiliency. CNA are complex distributed applications, vulnerable to several security issues affecting microservices and traditional cloud-based applications. For example, each microservice instance could be developed with different technologies e.g. programming languages and databases. This diversity of technologies increases the chances for security vulnerabilities in microservices. Moreover, the fast-paced development cycles of (CNA) increases the probability of insufficient security tests in the development pipelines, and consequent deployment of vulnerable microservices. Furthermore, cloud native environments are ephemeral, microservices are dynamically launched and de-registered, this factor creates a discoverability challenge for traditional security assessment techniques. Hence, security assessments in such environments require new approaches which are specifically adapted and integrated to CNA. In fact, such techniques are to be cloud native i.e. well integrated into the cloud's fabric. In this paper, we tackle the above-mentioned challenges through the introduction of a novel Security Control concept - the Security Gateway. To support the Security Gateway concept, two other concepts are proposed: dynamic document store and security health endpoints. We have implemented these concepts using cloud-native design patterns and integrated them into the CNA workflow. Our experimental evaluations validate the efficiency of our proposals, the time overhead due to the security gateway is minimal and the vulnerability detection rate surpasses that of traditional security assessment approaches. Our proposal can therefore be employed to secure CNA and microservice-based implementations.},
booktitle = {Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {171–180},
numpages = {10},
keywords = {security assessment, microservices, vulnerability detection, cloud native applications},
location = {Austin, Texas, USA},
series = {UCC '17}
}

@inproceedings{10.1145/3444757.3485108,
author = {Morais, Gabriel and Bork, Dominik and Adda, Mehdi},
title = {Towards an Ontology-Driven Approach to Model and Analyze Microservices Architectures},
year = {2021},
isbn = {9781450383141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3444757.3485108},
doi = {10.1145/3444757.3485108},
abstract = {Microservices Architectures (MSAs) are continuously replacing monolithic systems toward achieving more flexible and maintainable service-oriented software systems. However, the shift toward an MSA also requires a technological and managerial shift for its adopters. Architecting and managing MSAs represent unique challenges, including microservices' identification, interoperability, and reuse. To handle these challenges, we propose an Ontology-driven Conceptual Modelling approach, based on the Ontology of Microservices Architecture Concepts (OMSAC), for modelling and analyzing microservices-based systems. We show, how OMSAC-based conceptual models, stocked in a Stardog triple store, support Stakeholder-specific communication, documentation, and reuse. This paper reports on the application of our approach in three open-source MSA systems with a focus on microservices' discovery based on similarity metrics. Eventually, we compare the extracted similarity metrics derived from the application of machine learning techniques to the OMSAC models with a manual analysis performed by experts.},
booktitle = {Proceedings of the 13th International Conference on Management of Digital EcoSystems},
pages = {79–86},
numpages = {8},
keywords = {ontology, Stardog, Microservices, machine learning, OMSAC},
location = {Virtual Event, Tunisia},
series = {MEDES '21}
}

@inproceedings{10.1145/3379177.3388896,
author = {Wang, Bo and Boehm, Barry W.},
title = {Process Implications of Executable Domain Models for Microservices Development},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388896},
doi = {10.1145/3379177.3388896},
abstract = {Microservice architecture has been recognized as an important enabler for continuous development of many cloud-based systems. Code generation has been tried in the tool chain of building microservices. However, most existing tools generally do not consider the risks from continuous development.We have been developing a toolkit which generates microservices from application domain models. Our approach aligns development process to this toolkit and coordinates domain modeling activity over project life cycles. In this paper, we describe its framework and corresponding development process which eliminates delays brought by the uncertainty of a project at a relatively early stage. Several minimum viable products have been built upon the proposed approach during the past years, including automated generation of code from domain decomposition. Our result shows 10% saving of effort and fewer issues. Effort saving increases to 30% under an extreme condition with high-rate personnel turnover. We also discuss our findings on running these projects and raise discussion and questions for future enhancement.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {41–50},
numpages = {10},
keywords = {code generation, agile, continuous development, domain modeling, microservices},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@article{10.1145/3498336,
author = {Berenberg, Anna and Calder, Brad},
title = {Deployment Archetypes for Cloud Applications},
year = {2022},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3498336},
doi = {10.1145/3498336},
abstract = {This is a survey article that explores six Cloud-based deployment archetypes for Cloud applications and the tradeoffs between them to achieve high availability, low end-user latency, and acceptable costs. These are (1) Zonal, (2) Regional, (3) Multi-regional, (4) Global, (5) Hybrid, and (6) Multi-cloud deployment archetypes. The goal is to classify cloud applications into a set of deployment archetypes and deployment models that tradeoff their needs around availability, latency, and geographical constraints with a focus on serving applications. This enables application owners to better examine the tradeoffs of each deployment model and what is needed for achieving the availability and latency goals for their application.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {61},
numpages = {48},
keywords = {cloud architecture, cloud availability, cloud archetypes, Cloud deployments}
}

@inproceedings{10.1145/3342195.3387553,
author = {Sang, Bo and Roman, Pierre-Louis and Eugster, Patrick and Lu, Hui and Ravi, Srivatsan and Petri, Gustavo},
title = {PLASMA: Programmable Elasticity for Stateful Cloud Computing Applications},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342195.3387553},
doi = {10.1145/3342195.3387553},
abstract = {Developers are always on the lookout for simple solutions to manage their applications on cloud platforms. Major cloud providers have already been offering automatic elasticity management solutions (e.g., AWS Lambda, Azure durable function) to users. However, many cloud applications are stateful --- while executing, functions need to share their state with others. Providing elasticity for such stateful functions is much more challenging, as a deployment/elasticity decision for a stateful entity can strongly affect others in ways which are hard to predict without any application knowledge. Existing solutions either only support stateless applications (e.g., AWS Lambda) or only provide limited elasticity management (e.g., Azure durable function) to stateful applications.PLASMA (<u>P</u>rogrammable E<u>la</u>sticity for <u>S</u>tateful Cloud Co<u>m</u>puting <u>A</u>pplications) is a programming framework for elastic stateful cloud applications. It includes (1) an elasticity programming language as a second "level" of programming (complementing the main application programming language) for describing elasticity behavior, and (2) a novel semantics-aware elasticity management runtime that tracks program execution and acts upon application features as suggested by elasticity behavior. We have implemented 10+ applications with PLASMA. Extensive evaluation on Amazon AWS shows that PLASMA significantly improves their efficiency, e.g., achieving same performance as a vanilla setup with 25% fewer resources, or improving performance by 40% compared to the default setup.},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {42},
numpages = {15},
location = {Heraklion, Greece},
series = {EuroSys '20}
}

@inproceedings{10.1145/3147234.3148092,
author = {Martins, Lucas M. C. e and Filho, Francisco L. de Caldas and J\'{u}nior, Rafael T. de Sousa and Giozza, William F. and da Costa, Jo\~{a}o Paulo C.L.},
title = {Increasing the Dependability of IoT Middleware with Cloud Computing and Microservices},
year = {2017},
isbn = {9781450351959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147234.3148092},
doi = {10.1145/3147234.3148092},
abstract = {Internet of Things (IoT) has left the experimental field and is reaching the final consumer in areas such as residential automation, health, transportation and government support. Since these are applications intrinsically linked to the physical world, they require more attention in aspects related to their dependability. Focusing on its availability and reliability, we present a proposal to apply the Microservices architectural pattern in an IoT middleware with web services in the monolithic architecture. We describe the reengineering that must be done in this middleware and, finally, we analyze the advantages and disadvantages of this approach, highlighting the availability improvement, optimization of the infrastructure resources, the ease of maintenance and evolution, as well as the inclination to the elasticity that the architecture allows.},
booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {203–208},
numpages = {6},
keywords = {soa., internet of things (iot), middleware, cloud computing, microservices, dependability},
location = {Austin, Texas, USA},
series = {UCC '17 Companion}
}

@article{10.1145/3381452,
author = {Tsigkanos, Christos and Garriga, Martin and Baresi, Luciano and Ghezzi, Carlo},
title = {Cloud Deployment Tradeoffs for the Analysis of Spatially Distributed Internet of Things Systems},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3381452},
doi = {10.1145/3381452},
abstract = {Internet-enabled devices operating in the physical world are increasingly integrated in modern distributed systems. We focus on systems where the dynamics of spatial distribution is crucial; in such cases, devices may need to carry out complex computations (e.g., analyses) to check satisfaction of spatial requirements. The requirements are partly global—as the overall system should achieve certain goals—and partly individual, as each entity may have different goals. Assurance may be achieved by keeping a model of the system at runtime, monitoring events that lead to changes in the spatial environment, and performing requirements analysis. However, computationally intensive runtime spatial analysis cannot be supported by resource-constrained devices and may be offloaded to the cloud. In such a scenario, multiple challenges arise regarding resource allocation, cost, performance, among other dimensions. In particular, when the workload is unknown at the system’s design time, it may be difficult to guarantee application-service-level agreements, e.g., on response times. To address and reason on these challenges, we first instantiate complex computations as microservices and integrate them to an IoT-cloud architecture. Then, we propose alternative cloud deployments for such an architecture—based on virtual machines, containers, and the recent Functions-as-a-Service paradigm. Finally, we assess the feasibility and tradeoffs of the different deployments in terms of scalability, performance, cost, resource utilization, and more. We adopt a workload scenario from a known dataset of taxis roaming in Beijing, and we derive other workloads to represent unexpected request peaks and troughs. The approach may be replicated in the design process of similar classes of spatially distributed IoT systems.},
journal = {ACM Trans. Internet Technol.},
month = {apr},
articleno = {17},
numpages = {23}
}

@inproceedings{10.1145/3344948.3344952,
author = {Wang, Yuwei},
title = {Towards Service Discovery and Autonomic Version Management in Self-Healing Microservices Architecture},
year = {2019},
isbn = {9781450371421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344948.3344952},
doi = {10.1145/3344948.3344952},
abstract = {Microservices architectures (MSAs) contribute to building complex distributed systems by decomposing monolithic systems into a set of independent microservices. This makes it possible to design, develop and deploy scalable and flexible systems. However, various unexpected changes could happen during execution, such as a service upgrade, a sudden increase of traffic, or an infrastructural failure. In this cases, how to react autonomously to these changes without outages becomes a challenge to consider. A PhD project has been launched to propose a self-healing microservices architecture, which can adapt dynamically to inside and outside changes without human intervention. In this paper, we present the first results of a systematic state of the art in the field of self-healing MSA systems. As an entry point of our research, we focus on self-healing triggered by upgrade changes. The initial contribution is a new component of a version manager in our self-healing MSA solution, in relation with service discovery elements. This approach can provide an autonomic version management on both the application level and the system level, and helps to control services upgrading changes. We plan to validate our proposition in a company project use case by deploying it in an emulated production environment, and applying a chaos engineering approach.},
booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
pages = {63–66},
numpages = {4},
keywords = {industrialization, microservices, version management, software architecture, service discovery, self-healing},
location = {Paris, France},
series = {ECSA '19}
}

@article{10.1145/3418899,
author = {Brondolin, Rolando and Santambrogio, Marco D.},
title = {A Black-Box Monitoring Approach to Measure Microservices Runtime Performance},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3418899},
doi = {10.1145/3418899},
abstract = {Microservices changed cloud computing by moving the applications’ complexity from one monolithic executable to thousands of network interactions between small components. Given the increasing deployment sizes, the architectural exploitation challenges, and the impact on data-centers’ power consumption, we need to efficiently track this complexity. Within this article, we propose a black-box monitoring approach to track microservices at scale, focusing on architectural metrics, power consumption, application performance, and network performance. The proposed approach is transparent w.r.t. the monitored applications, generates less overhead w.r.t. black-box approaches available in the state-of-the-art, and provides fine-grain accurate metrics.},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
articleno = {34},
numpages = {26},
keywords = {performance monitoring, power attribution, kubernetes, network performance monitoring, Microservices, docker, cloud computing}
}

@inproceedings{10.1145/3491204.3527483,
author = {Beck, Samuel and Frank, Sebastian and Hakamian, Alireza and van Hoorn, Andr\'{e}},
title = {How is Transient Behavior Addressed in Practice? Insights from a Series of Expert Interviews},
year = {2022},
isbn = {9781450391597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491204.3527483},
doi = {10.1145/3491204.3527483},
abstract = {Transient behavior occurs when a running software system changes from one steady-state to another. In microservice systems, such disruptions can, for example, be caused by continuous deployment, self-adaptation, and various failures. Although transient behavior could be captured in non-functional requirements, little is known of how that is handled in practice. Our objective was to study how architects and engineers approach runtime disruptions, which challenges they face, whether or not they specify transient behavior, and how currently employed tools and methods can be improved. To this end, we conducted semi-structured interviews with five experienced practitioners from major companies in Germany. We found that a big challenge in the industry is a lack of awareness of transient behavior by software stakeholders. Consequently, they often do not consider specifying it in non-functional requirements. Additionally, better tooling is needed to reduce the effort of analyzing transient behavior. We present two prototypes that we developed corresponding to these findings to improve the current situation. Beyond that, the insights we present can serve as pointers for interesting research directions for other researchers.},
booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
pages = {105–112},
numpages = {8},
keywords = {transient behavior, non-functional requirements, microservices},
location = {Bejing, China},
series = {ICPE '22}
}

@article{10.1145/3510411,
author = {Korala, Harindu and Georgakopoulos, Dimitrios and Jayaraman, Prem Prakash and Yavari, Ali},
title = {A Survey of Techniques for Fulfilling the Time-Bound Requirements of Time-Sensitive IoT Applications},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {11s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3510411},
doi = {10.1145/3510411},
abstract = {This article surveys existing techniques for meeting the time-bound requirements of time-sensitive applications in the Internet of Things (IoT). To provide the foundation for identifying and classifying relevant techniques, we present three sample time-sensitive IoT applications and their time-bound requirements, describe the main computation and network resources in IoT that can be used to process such applications, and identify the main challenges in meeting their time-bound requirements. Based on these, the article presents a comprehensive literature review of existing techniques and tools that can help meet application-specific time-bound requirements in IoT. The article also includes a gap analysis in existing research outcomes and proposes research directions for bridging the remaining research gaps in supporting time-sensitive IoT applications.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {228},
numpages = {36},
keywords = {Internet of Things (IoT), time sensitive, time-bound}
}

@inproceedings{10.5555/3172795.3172827,
author = {Pourmajidi, William and Steinbacher, John and Erwin, Tony and Miranskyy, Andriy},
title = {On Challenges of Cloud Monitoring},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cloud services are becoming increasingly popular: 60% of information technology spending in 2016 was Cloud-based, and the size of the public Cloud service market will reach $236B by 2020. To ensure reliable operation of the Cloud services, one must monitor their health.While a number of research challenges in the area of Cloud monitoring have been solved, problems are remaining. This prompted us to highlight three areas, which cause problems to practitioners and require further research. These three areas are as follows: A) defining health states of Cloud systems, B) creating unified monitoring environments, and C) establishing high availability strategies.In this paper we provide details of these areas and suggest a number of potential solutions to the challenges. We also show that Cloud monitoring presents exciting opportunities for novel research and practice.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {259–265},
numpages = {7},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}

@inproceedings{10.1145/3416505.3423560,
author = {Lomio, Francesco and Baselga, Diego Mart\'{\i}nez and Moreschini, Sergio and Huttunen, Heikki and Taibi, Davide},
title = {RARE: A Labeled Dataset for Cloud-Native Memory Anomalies},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423560},
doi = {10.1145/3416505.3423560},
abstract = {Anomaly detection has been attracting interest from both the industry and the research community for many years, as the number of published papers and services adopted grew exponentially over the last decade. One of the reasons behind this is the wide adoption of cloud systems from the majority of players in multiple industries, such as online shopping, advertisement or remote computing. In this work we propose a Dataset foR cloud-nAtive memoRy anomaliEs: RARE. It includes labelled anomaly time-series data, comprising of over 900 unique metrics. This dataset has been generated using a microservice for injecting artificial byte stream in order to overload the nodes, provoking memory anomalies, which in some cases resulted in a crash. The system was built using a Kafka server deployed on a Kubernetes system. Moreover, in order to get access and download the metrics related to the server, we utilised Prometheus. In this paper we present a dataset that can be used coupled with machine learning algorithms for detecting anomalies in a cloud based system. The dataset will be available in the form of CSV file through an online repository. Moreover, we also included an example of application using a Random Forest algorithm for classifying the data as anomalous or not. The goal of the RARE dataset is to help in the development of more accurate and reliable machine learning methods for anomaly detection in cloud based systems.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {19–24},
numpages = {6},
keywords = {machine learnin, self healing, Dataset, anomaly detection, kubernetes},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@inproceedings{10.1145/3531056.3542769,
author = {Mwotil, Alex and Bainomugisha, Engineer and Araka, Stephen G.M.},
title = {Mira: An Application Containerisation Pipeline for Small Software Development Teams in Low Resource Settings},
year = {2022},
isbn = {9781450396639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531056.3542769},
doi = {10.1145/3531056.3542769},
abstract = {Cloud native applications leverage Development and Operation (DevOps), microservice architectures and containerisation for primarily availability, resilience and scalability reasons. Small developer teams in low resource settings have unique DevOps needs and harnessing its principles and practices is technically challenging and distinctly difficult in these contexts. We conducted a survey with professional developers, students and researchers situated and working in a low resource setting and the results indicate that these principles and practices are relatively new. In application containerisation, an operating system virtualisation method that can significantly optimize the use of computing resources, the respondents indicated challenges in the process steps. Particularly, small developer teams in low resource settings require custom tools and abstractions for software development and delivery automation. Informed by the developer needs, we designed and developed a custom automated containerisation pipeline, mira, for a managed cloud native platform situated in a low-resource setting. We validate mira against 6 major application frameworks, tools and/or languages and successful deployment of the resultant applications onto a cloud native platform.},
booktitle = {Proceedings of the Federated Africa and Middle East Conference on Software Engineering},
pages = {31–38},
numpages = {8},
keywords = {orchestration, docker, cloud, containers, automation, cloud native},
location = {Cairo-Kampala, Egypt},
series = {FAMECSE '22}
}

@inproceedings{10.1145/2993412.3004852,
author = {D\'{\i}az, Jessica and P\'{e}rez, Jennifer and P\'{e}rez, Jorge and Garbajosa, Juan},
title = {Conceptualizing a Framework for Cyber-Physical Systems of Systems Development and Deployment},
year = {2016},
isbn = {9781450347815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993412.3004852},
doi = {10.1145/2993412.3004852},
abstract = {Cyber-physical systems (CPS) refer to the next generation of embedded ICT systems that are interconnected, collaborative and that provide users and businesses with a wide range of smart applications and services. Software in CPS applications ranges from small systems to large systems, aka. Systems of Systems (SoS), such as smart grids and cities. CPSoS require managing massive amounts of data, being aware of their emerging behavior, and scaling out to progressively evolve and add new systems. Cloud computing supports processing and storing massive amounts of data, hosting and delivering services, and configuring self-provisioned resources. Therefore, cloud computing is the natural candidate to solve CPSoS needs. However, the diversity of platforms and the low-level cloud programming models make difficult to find a common solution for the development and deployment of CPSoS. This paper presents the architectural foundations of a cloud-centric framework for automating the development and deployment of CPSoS service applications to converge towards a common open service platform for CPSoS applications. This framework relies on the well-known qualities of the microservices architecture style, the autonomic computing paradigm, and the model-driven software development approach. Its implementation and validation is on-going at two European and national projects.},
booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
articleno = {1},
numpages = {7},
keywords = {microservices, cyber-physical systems, model-driven development, software architecture, cloud computing},
location = {Copenhagen, Denmark},
series = {ECSAW '16}
}

@inproceedings{10.1145/3205651.3208253,
author = {Khalloof, Hatem and Jakob, Wilfried and Liu, Jianlei and Braun, Eric and Shahoud, Shadi and Duepmeier, Clemens and Hagenmeyer, Veit},
title = {A Generic Distributed Microservices and Container Based Framework for Metaheuristic Optimization},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208253},
doi = {10.1145/3205651.3208253},
abstract = {In recent years, metaheuristics have been a convincing solution for solving many types of complex optimization problems. Efficient execution for the most variants of metaheuristics e.g. Evolutionary Algorithms (EAs) or Swarm Optimization can require lots of computational power depending on the complexity of the application. For maximizing performance, parallelization of metaheuristic algorithms represents a meaningful approach, especially for EAs featuring an inherent parallelism. However, the majority of existing distributed optimization frameworks are implemented as monolithic and non-distributed applications running on one computer instead of using the computing power of computer clusters. Additionally, the application typically cannot easily work dynamically together with other tools and services like single simulators or combinations of simulators for multi-domain simulations. In the present paper, a new distributed framework for population-based metaheuristics, which can run highly parallelized optimizations on large scale computing clusters is introduced. The framework exploits and combines two lightweight technologies namely container virtualization and microservices for a fully automated and highly scalable solution. Another main advantage of the framework is that it allows plugging in and out different metaheuristic optimization algorithms and services via its modular distributed architecture. In order to validate the new design and implementation, the EA GLEAM (General Learning Evolutionary Algorithm and Method) [2, 3] is integrated into the framework and deployed on a cluster with 4 nodes and 128 cores for benchmarking. The tested master-slave parallelization of this EA shows considerable low overhead times and hence paves the way for future applications in, e.g., smart energy systems.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1363–1370},
numpages = {8},
keywords = {scalability, microservices, virtualization, cluster, evolutionary algorithms, parallel computing, container, metaheuristic optimization},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@inproceedings{10.1109/TechDebt.2019.00026,
author = {de Toledo, Saulo S. and Martini, Antonio and Przybyszewska, Agata and Sj\o{}berg, Dag I. K.},
title = {Architectural Technical Debt in Microservices: A Case Study in a Large Company},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/TechDebt.2019.00026},
doi = {10.1109/TechDebt.2019.00026},
abstract = {Introduction: Software companies aim to achieve continuous delivery to constantly provide value to their customers. A popular strategy is to use microservices architecture. However, such an architecture is also subject to debt, which hinders the continuous delivery process and thus negatively affects the software released to the customers.Objectives: The aim of this study is to identify issues, solutions and risks related to Architecture Technical Debt in microservices.Method: We conducted an exploratory case study of a real life project with about 1000 services in a large, international company. Through qualitative analysis of documents and interviews, we investigated Architecture Technical Debt in the communication layer of a system with microservices architecture.Results: Our main contributions are a list of Architecture Technical Debt issues specific for the communication layer in a system with microservices architecture, as well as their associated negative impact (interest), a solution to repay the debt and the its cost (principal). Among the found Architecture Technical Debt issues were the existence of business logic in the communication layer and a high amount of point-to-point connections between services. The studied solution consists of the implementation of different canonical models specific to different domains, the removal of business logic from the communication layer, and migration from services to use the communication layer correctly. We also contributed with a list of possible risks that can affect the payment of the debt, as lack of funding and inadequate prioritization.Conclusion: We found issues, solutions and possible risks that are specific for microservices architectures not yet encountered in the current literature. Our results may be useful for practitioners that want to avoid or repay Technical Debt in their microservices architecture.},
booktitle = {Proceedings of the Second International Conference on Technical Debt},
pages = {78–87},
numpages = {10},
keywords = {microservices, technical debt, case study, architecture},
location = {Montreal, Quebec, Canada},
series = {TechDebt '19}
}

@inproceedings{10.1145/3219819.3219834,
author = {Staar, Peter W J and Dolfi, Michele and Auer, Christoph and Bekas, Costas},
title = {Corpus Conversion Service: A Machine Learning Platform to Ingest Documents at Scale},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219834},
doi = {10.1145/3219819.3219834},
abstract = {Over the past few decades, the amount of scientific articles and technical literature has increased exponentially in size. Consequently, there is a great need for systems that can ingest these documents at scale and make the contained knowledge discoverable. Unfortunately, both the format of these documents (e.g. the PDF format or bitmap images) as well as the presentation of the data (e.g. complex tables) make the extraction of qualitative and quantitive data extremely challenging. In this paper, we present a modular, cloud-based platform to ingest documents at scale. This platform, called the Corpus Conversion Service (CCS), implements a pipeline which allows users to parse and annotate documents (i.e. collect ground-truth), train machine-learning classification algorithms and ultimately convert any type of PDF or bitmap-documents to a structured content representation format. We will show that each of the modules is scalable due to an asynchronous microservice architecture and can therefore handle massive amounts of documents. Furthermore, we will show that our capability to gather groundtruth is accelerated by machine-learning algorithms by at least one order of magnitude. This allows us to both gather large amounts of ground-truth in very little time and obtain very good precision/recall metrics in the range of 99% with regard to content conversion to structured output. The CCS platform is currently deployed on IBM internal infrastructure and serving more than 250 active users for knowledge-engineering project engagements.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {774–782},
numpages = {9},
keywords = {cloud architecture, document conversion, artificial intelligence, knowledge ingestion, ibm, asynchronous architecture, machine learning, ai, table processing, deep learning, cloud computing, pdf, ibm research},
location = {London, United Kingdom},
series = {KDD '18}
}

@article{10.1145/3425866,
author = {Liu, Xuanzhe and Wang, Shangguang and Ma, Yun and Zhang, Ying and Mei, Qiaozhu and Liu, Yunxin and Huang, Gang},
title = {Operating Systems for Resource-Adaptive Intelligent Software: Challenges and Opportunities},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3425866},
doi = {10.1145/3425866},
abstract = {The past decades witnessed the fast and wide deployment of Internet. The Internet has bred the ubiquitous computing environment that is spanning the cloud, edge, mobile devices, and IoT. Software running over such a ubiquitous computing environment environment is eating the world. A recently emerging trend of Internet-based software systems is “resource adaptive,” i.e., software systems should be robust and intelligent enough to the changes of heterogeneous resources, both physical and logical, provided by their running environment. To keep pace of such a trend, we argue that some considerations should be taken into account for the future operating system design and implementation. From the structural perspective, rather than the “monolithic OS” that manages the aggregated resources on the single machine, the OS should be dynamically composed over the distributed resources and flexibly adapt to the resource and environment changes. Meanwhile, the OS should leverage advanced machine/deep learning techniques to derive configurations and policies and automatically learn to tune itself and schedule resources. This article envisions our recent thinking of the new OS abstraction, namely, ServiceOS, for future resource-adaptive intelligent software systems. The idea of ServiceOS is inspired by the delivery model of “Software-as-a-Service” that is supported by the Service-Oriented Architecture (SOA). The key principle of ServiceOS is based on resource disaggregation, resource provisioning as a service, and learning-based resource scheduling and allocation. The major goal of this article is not providing an immediately deployable OS. Instead, we aim to summarize the challenges and potentially promising opportunities and try to provide some practical implications for researchers and practitioners.},
journal = {ACM Trans. Internet Technol.},
month = {mar},
articleno = {27},
numpages = {19},
keywords = {Operating systems, machine learning, service-oriented, resource disaggregation}
}

@proceedings{10.1145/3308560,
title = {WWW '19: Companion Proceedings of The 2019 World Wide Web Conference},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to <i>The Web Conference 2019</i>. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, USA}
}

@inproceedings{10.1145/3342280.3342287,
author = {Leng, Xue and Juang, Tzung-Han and Chen, Yan and Liu, Han},
title = {AOMO: An AI-Aided Optimizer for Microservices Orchestration},
year = {2019},
isbn = {9781450368865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342280.3342287},
doi = {10.1145/3342280.3342287},
booktitle = {Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos},
pages = {1–2},
numpages = {2},
keywords = {Microservices, Orchestration Optimization},
location = {Beijing, China},
series = {SIGCOMM Posters and Demos '19}
}

@inbook{10.1145/3277669.3277699,
title = {References},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277699},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inproceedings{10.1145/3457784.3457835,
author = {Ahmadi, Ahmadi and Budiardjo, Eko K. and Mahatma, Kodrat},
title = {Software Craftsmanship Skill Using Extreme Programming for Quality Improvement: A Case of Very Small Software Organization},
year = {2021},
isbn = {9781450388825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457784.3457835},
doi = {10.1145/3457784.3457835},
abstract = {Software product release often sacrifices quality concerns and produces messy code to reach the market quickly. At some point, the software becomes difficult to maintain, and reengineering is an available option to improve software quality. By finding a way to improve our software product quality effectively, we explore the available software reengineering methods that match the business needs. This paper presents our case, a product development improvement effort in a very small software organization with limited resources and a tight development schedule. Our research shows that with careful software redesigning and implementing XP practices, supported by a well-crafted software manifesto, we can ensure software code quality improvement is achieved efficiently.},
booktitle = {2021 10th International Conference on Software and Computer Applications},
pages = {94–99},
numpages = {6},
keywords = {very small software organization, software craftsmanship, software reengineering, well-crafted software, software quality, extreme programming},
location = {Kuala Lumpur, Malaysia},
series = {ICSCA 2021}
}

@inbook{10.1145/3277669.3277684,
title = {Reflection on the Kernel},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277684},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277697,
title = {Reaching out to the Future},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277697},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277691,
title = {Putting the Practices Together},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277691},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277672,
title = {From Programming to Software Engineering},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277672},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277689,
title = {Running with Use Case Lite},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277689},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277679,
title = {Applying Essence in the Small},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277679},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@book{10.1145/3277669,
author = {Jacobson, Ivar and Lawson, Harold "Bud" and Ng, Pan-Wei and McMahon, Paul E. and Goedicke, Michael},
title = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.}
}

@inbook{10.1145/3277669.3277673,
title = {Software Engineering Methods and Practices},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277673},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inproceedings{10.1145/3477314.3507221,
author = {M\"{u}ller, Rodrigo H. and Meinhardt, Cristina and Mendizabal, Odorico M.},
title = {An Architecture Proposal for Checkpoint/Restore on Stateful Containers},
year = {2022},
isbn = {9781450387132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477314.3507221},
doi = {10.1145/3477314.3507221},
abstract = {Containers have been widely adopted for the development of microservices and cloud-native applications. In parts, this popularization stems from the container orchestration platforms support, facilitating the development and continuously integrating large-scale applications. However, the established techniques offered by orchestration tools to replicate containers are insufficient to provide high availability and strong consistency for stateful containers. Thus, this paper proposes a Checkpoint/Restore (C/R) service to achieve fault-tolerance on stateful containers. Our service aims to eliminate the checkpoint management burden by adding a transparent C/R service into container orchestration platforms. The checkpointing service, implemented as an interceptor, is responsible for taking snapshots of application containers and coordinating the checkpoint execution with the delivery of requests. In case of faults, a new application container is automatically built from a recent snapshot, and the interceptor resumes the delivery of client requests since that checkpoint. A Proof of Concept using a Kubernetes cluster is implemented and corroborates for the feasibility of the C/R. Some challenges and future directions are discussed.},
booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
pages = {267–270},
numpages = {4},
keywords = {checkpoint/restart, kubernetes, microservices, stateful services},
location = {Virtual Event},
series = {SAC '22}
}

@inbook{10.1145/3277669.3277682,
title = {Developing with Essence},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277682},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@article{10.1145/3267468,
author = {Anisetti, Marco and Ardagna, Claudio and Damiani, Ernesto and Polegri, Gianluca},
title = {Test-Based Security Certification of Composite Services},
year = {2018},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1559-1131},
url = {https://doi.org/10.1145/3267468},
doi = {10.1145/3267468},
abstract = {The diffusion of service-based and cloud-based systems has created a scenario where software is often made available as services, offered as commodities over corporate networks or the global net. This scenario supports the definition of business processes as composite services, which are implemented via either static or runtime composition of offerings provided by different suppliers. Fast and accurate evaluation of services’ security properties becomes then a fundamental requirement and is nowadays part of the software development process. In this article, we show how the verification of security properties of composite services can be handled by test-based security certification and built to be effective and efficient in dynamic composition scenarios. Our approach builds on existing security certification schemes for monolithic services and extends them towards service compositions. It virtually certifies composite services, starting from certificates awarded to the component services. We describe three heuristic algorithms for generating runtime test-based evidence of the composite service holding the properties. These algorithms are compared with the corresponding exhaustive algorithm to evaluate their quality and performance. We also evaluate the proposed approach in a real-world industrial scenario, which considers ENGpay online payment system of Engineering Ingegneria Informatica S.p.A. The proposed industrial evaluation presents the utility and generality of the proposed approach by showing how certification results can be used as a basis to establish compliance to Payment Card Industry Data Security Standard.},
journal = {ACM Trans. Web},
month = {dec},
articleno = {3},
numpages = {43},
keywords = {model-based testing, security certification, Cloud, service-oriented architecture, software-as-a-service, web services, service composition}
}

@inbook{10.1145/3277669.3277678,
title = {Reflection on Theory},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277678},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@article{10.1145/3152529,
author = {Leung, Andrew and Spyker, Andrew and Bozarth, Tim},
title = {Titus: Introducing Containers to the Netflix Cloud},
year = {2018},
issue_date = {February 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {61},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3152529},
doi = {10.1145/3152529},
abstract = {Approaching container adoption in an already cloud-native infrastructure.},
journal = {Commun. ACM},
month = {jan},
pages = {38–45},
numpages = {8}
}

@inproceedings{10.1145/3465481.3470066,
author = {Cavalcanti, Marcos and Inacio, Pedro and Freire, Mario},
title = {Performance Evaluation of Container-Level Anomaly-Based Intrusion Detection Systems for Multi-Tenant Applications Using Machine Learning Algorithms},
year = {2021},
isbn = {9781450390514},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465481.3470066},
doi = {10.1145/3465481.3470066},
abstract = {The virtualization of computing resources provided by containers has gained increasing attention and has been widely used in cloud computing. This new demand for container technology has been growing and the use of Docker and Kubernetes is considerable. According to recent technology surveys, containers are now mainstream. However, currently, one of the major challenges rises from the fact that multiple containers, with different owners, may cohabit on the same host. In container-based multi-tenant environments, security issues are of major concern. In this paper we investigate the performance of container-level anomaly-based intrusion detection systems for multi-tenant applications. We investigate the use of Bag of System Calls (BoSC) technique and the sliding window with the classifier and we consider eight machine learning algorithms for classification purposes. We show that among the eight machine learning algorithms, the best classification results are obtained with Decision Tree and Random Forest which lead to an F-Measure of 99.8%, using a sliding window with a size of 30 and the BoSC algorithm in both cases. We also show that, although both Decision Tree and Random Forest algorithms leads to the best classification results, the Decision Tree algorithm has a shorter execution time and consumes less CPU and memory than the Random Forest.},
booktitle = {Proceedings of the 16th International Conference on Availability, Reliability and Security},
articleno = {109},
numpages = {9},
keywords = {Containers, Machine Learning Algorithms, Intrusion Detection Systems, System Calls},
location = {Vienna, Austria},
series = {ARES 21}
}

@article{10.1145/3155112.3158370,
author = {Leung, Andrew and Spyker, Andrew and Bozarth, Tim},
title = {Titus: Introducing Containers to the Netflix Cloud: Approaching Container Adoption in an Already Cloud-Native Infrastructure},
year = {2017},
issue_date = {September-October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {1542-7730},
url = {https://doi.org/10.1145/3155112.3158370},
doi = {10.1145/3155112.3158370},
abstract = {We believe our approach has enabled Netflix to quickly adopt and benefit from containers. Though the details may be Netflix-specific, the approach of providing low-friction container adoption by integrating with existing infrastructure and working with the right early adopters can be a successful strategy for any organization looking to adopt containers.},
journal = {Queue},
month = {oct},
pages = {53–77},
numpages = {25}
}

@inproceedings{10.5555/3291291.3291321,
author = {Khazaei, Hamzeh and Ghanbari, Alireza and Litoiu, Marin},
title = {Adaptation as a Service},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {Current and emerging complex systems of many types including but not limited to big data systems, web-based systems, data centers and cloud infrastructure, social networks and the Internet of Things (IoT) have increasingly distributed and dynamic architecture that provide unprecedented flexibility in creating and supporting applications. However, such highly distributed architecture also increases the complexity of end-to-end management of such systems. Due to the sheer complexity, uncertainty and at the same time programmability of cloud environments, microservices and finally big data analytics, it is now required, and possible, to enable autonomic management in distributed systems in a dependable manner. In this paper, we argue that building autonomic management systems is a challenging task and requires its own set of expertise and knowledge. Therefore, in the light of current challenges, available enablers and recent successful stories, we propose the idea of moving from self-adaptation to ADaptation-as-a-Service (ADaaS).},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {282–288},
numpages = {7},
keywords = {microservices, cloud computing, software engineering, eslf-adaptation, containers, adaptation as a service},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@inbook{10.1145/3277669.3277687,
title = {Running with Scrum},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277687},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@article{10.1145/3539606,
author = {Carri\'{o}n, Carmen},
title = {Kubernetes Scheduling: Taxonomy, Ongoing Issues and Challenges},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3539606},
doi = {10.1145/3539606},
abstract = {Continuous integration enables the development of microservices-based applications using container virtualization technology. Container orchestration systems such as Kubernetes, which has become the de facto standard, simplify the deployment of container-based applications. However, developing efficient and well-defined orchestration systems is a challenge. This paper focuses specifically on the scheduler, a key orchestrator task that assigns physical resources to containers. Scheduling approaches are designed based on different Quality of Service (QoS) parameters to provide limited response time, efficient energy consumption, better resource utilization, and other things. This paper aims to establish insight knowledge into Kubernetes scheduling, find the main gaps, and thus guide future research in the area. Therefore, we conduct a study of empirical research on Kubernetes scheduling techniques and present a new taxonomy for Kubernetes scheduling. The challenges, future direction, and research opportunities are also discussed.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = {may},
keywords = {containers, survey, scheduling, orchestration, Kubernetes}
}

@article{10.1145/3341145,
author = {Duc, Thang Le and Leiva, Rafael Garc\'{\i}a and Casari, Paolo and \"{O}stberg, Per-Olov},
title = {Machine Learning Methods for Reliable Resource Provisioning in Edge-Cloud Computing: A Survey},
year = {2019},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3341145},
doi = {10.1145/3341145},
abstract = {Large-scale software systems are currently designed as distributed entities and deployed in cloud data centers. To overcome the limitations inherent to this type of deployment, applications are increasingly being supplemented with components instantiated closer to the edges of networks—a paradigm known as edge computing. The problem of how to efficiently orchestrate combined edge-cloud applications is, however, incompletely understood, and a wide range of techniques for resource and application management are currently in use.This article investigates the problem of reliable resource provisioning in joint edge-cloud environments, and surveys technologies, mechanisms, and methods that can be used to improve the reliability of distributed applications in diverse and heterogeneous network environments. Due to the complexity of the problem, special emphasis is placed on solutions to the characterization, management, and control of complex distributed applications using machine learning approaches. The survey is structured around a decomposition of the reliable resource provisioning problem into three categories of techniques: workload characterization and prediction, component placement and system consolidation, and application elasticity and remediation. Survey results are presented along with a problem-oriented discussion of the state-of-the-art. A summary of identified challenges and an outline of future research directions are presented to conclude the article.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {94},
numpages = {39},
keywords = {placement, consolidation, Reliability, optimization, machine learning, cloud computing, remediation, edge computing, distributed systems, autoscaling}
}

@inproceedings{10.1145/3410992.3410999,
author = {Krivic, Petar and Guberovic, Emanuel and Zarko, Ivana Podnar and Cavrak, Igor},
title = {Evaluation of Selected Technologies for the Implementation of Meter Data Management System},
year = {2020},
isbn = {9781450387583},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410992.3410999},
doi = {10.1145/3410992.3410999},
abstract = {Implementation of an efficient meter data management system presents a challenging task since it has to process and store a large number of incoming time-series data entries in almost real-time. A number of solutions for efficient processing and storage of big data streams are today available as open source or commercial software. However, the choice of the most applicable solution highly depends on the requirements of a specific use case scenario since the performance of the aforementioned solutions often vary depending on the specific use-case parameters (e.g. incoming data frequency, average size of a single data entry, etc.). Thus, in this paper we examine different platforms adequate for the implementation of a smart metering data acquisition system, to identify the most efficient ones among the considered candidates. The most important requirement of our meter data management system is to offer a stable solution that processes and stores high volumes of continuously incoming data readings with minimal loss-rate. For this purpose we propose a modular solution where components communicate over a message-queuing system, while the ultimate data repository is a NoSQL database. After carrying out all the specifically designed performance tests, we identify the following platforms as the most promising ones to implement our smart metering solution: Kafka as the messaging broker and time-series database InfluxDB. Finally, we verified that our MDMS successfully processes and stores 2.5 M data entries in a time period under eight minutes which confirms its targeted performance efficiency.},
booktitle = {Proceedings of the 10th International Conference on the Internet of Things},
articleno = {19},
numpages = {8},
keywords = {smart metering, MDMS, InfluxDB, Kafka, time-series data},
location = {Malm\"{o}, Sweden},
series = {IoT '20}
}

@inproceedings{10.1145/3472883.3486976,
author = {Lim, Soo Yee and Stelea, Bogdan and Han, Xueyuan and Pasquier, Thomas},
title = {Secure Namespaced Kernel Audit for Containers},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3486976},
doi = {10.1145/3472883.3486976},
abstract = {Despite the wide usage of container-based cloud computing, container auditing for security analysis relies mostly on built-in host audit systems, which often lack the ability to capture high-fidelity container logs. State-of-the-art reference-monitor-based audit techniques greatly improve the quality of audit logs, but their system-wide architecture is too costly to be adapted for individual containers. Moreover, these techniques typically require extensive kernel modifications, making it difficult to deploy in practical settings.In this paper, we present saBPF (secure audit BPF), an extension of the eBPF framework capable of deploying secure system-level audit mechanisms at the container granularity. We demonstrate the practicality of saBPF in Kubernetes by designing an audit framework, an intrusion detection system, and a lightweight access control mechanism. We evaluate saBPF and show that it is comparable in performance and security guarantees to audit systems from the literature that are implemented directly in the kernel.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {518–532},
numpages = {15},
keywords = {auditing, provenance, container, eBPF},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@inproceedings{10.1145/3185768.3186308,
author = {van Eyk, Erwin and Iosup, Alexandru and Abad, Cristina L. and Grohmann, Johannes and Eismann, Simon},
title = {A SPEC RG Cloud Group's Vision on the Performance Challenges of FaaS Cloud Architectures},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185768.3186308},
doi = {10.1145/3185768.3186308},
abstract = {As a key part of the serverless computing paradigm, Function-as-a-Service (FaaS) platforms enable users to run arbitrary functions without being concerned about operational issues. However, there are several performance-related issues surrounding the state-of-the-art FaaS platforms that can deter widespread adoption of FaaS, including sizeable overheads, unreliable performance, and new forms of the cost-performance trade-off. In this work we, the SPEC RG Cloud Group, identify six performance-related challenges that arise specifically in this FaaS model, and present our roadmap to tackle these problems in the near future. This paper aims at motivating the community to solve these challenges together.},
booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {21–24},
numpages = {4},
keywords = {function-as-a-service, FaaS, benchmarking, serverless computing, performance evaluation, reference architecture},
location = {Berlin, Germany},
series = {ICPE '18}
}

@inproceedings{10.1145/3383219.3383276,
author = {Li, Shanshan and Xu, Qianwen and Hou, Peiyu and Chen, Xiudi and Wang, Yanze and Zhang, He and Rong, Guoping},
title = {Exploring the Challenges of Developing and Operating Consortium Blockchains: A Case Study},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383276},
doi = {10.1145/3383219.3383276},
abstract = {Blockchain and smart contracts are being embraced by more and more industrial practitioners in multiple domains including agriculture, manufacturing, and healthcare. As a distributed, immutable, and partly public ledger, the consortium blockchain demonstrates its potential to enable trustworthy interoperability and collaboration between organizations. However, the mismatch between the unruled software engineering practices and the increased interest of the consortium blockchain technology may pose threats to the quality of systems implemented. To mitigate the possible threats, this study takes the angle of software engineering to systematically understand the challenges and possible solutions in terms of developing and operating a consortium blockchain-based system. For this purpose, we conducted a case study on a typical consortium blockchain-based system and exhaustively collected the data by two rounds in-depth interviews on practitioners of different roles in the case project. Based on the data analysis, eight pairs of challenges and potential solutions were identified, which cover the phases of the development and operation of consortium blockchains. Moreover, we also captured two implications after further analysis of the findings, which worth the special attention of researchers in the near future, i.e. DevOps and microservices for blockchain or smart contracts.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {398–404},
numpages = {7},
keywords = {DevOps, smart contracts, microservices, Consortium blockchain},
location = {Trondheim, Norway},
series = {EASE '20}
}

@inproceedings{10.1145/3011141.3011179,
author = {de Camargo, Andr\'{e} and Salvadori, Ivan and Mello, Ronaldo dos Santos and Siqueira, Frank},
title = {An Architecture to Automate Performance Tests on Microservices},
year = {2016},
isbn = {9781450348072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011141.3011179},
doi = {10.1145/3011141.3011179},
abstract = {The microservices architecture provides a new approach to develop applications. As opposed to monolithic applications, in which the application comprises a single software artifact, an application based on the microservices architecture is composed by a set of services, each one designed to perform a single and well-defined task. These services allow the development team to decouple several parts of the application using different frameworks, languages and hardware for each part of the system. One of the drawbacks for adopting the microservices architecture to develop applications is testability. In a single application test boundaries can be more easily established and tend to be more stable as the application evolves, while with microservices we can have a set of hundreds of services that operate together and are prone to change more rapidly. Each one of these services needs to be tested and updated as the service changes. In addition, the different characteristics of these services such as languages, frameworks or the used infrastructure have to be considered in the testing phase. Performance tests are applied to assure that a particular software complies with a set of non-functional requirements such as throughput and response time. These metrics are important to ensure that business constraints are respected and to help finding performance bottlenecks. In this paper, we present a new approach to allow the performance tests to be executed in an automated way, with each microservice providing a test specification that is used to perform tests. Along with the architecture, we also provide a framework that implements some key concepts of this architecture. This framework is available as an open source project1.},
booktitle = {Proceedings of the 18th International Conference on Information Integration and Web-Based Applications and Services},
pages = {422–429},
numpages = {8},
keywords = {microservices, performance test, test automation},
location = {Singapore, Singapore},
series = {iiWAS '16}
}

@inproceedings{10.1145/3465480.3466919,
author = {Laigner, Rodrigo and Zhou, Yongluan and Salles, Marcos Antonio Vaz},
title = {A Distributed Database System for Event-Based Microservices},
year = {2021},
isbn = {9781450385558},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465480.3466919},
doi = {10.1145/3465480.3466919},
abstract = {Microservice architectures are an emerging industrial approach to build large scale and event-based systems. In this architectural style, an application is functionally partitioned into several small and autonomous building blocks, so-called microservices, communicating and exchanging data with each other via events.By pursuing a model where fault isolation is enforced at microservice level, each microservice manages their own database, thus database systems are not shared across microservices. Developers end up encoding substantial data management logic in the application-tier and encountering a series of challenges on enforcing data integrity and maintaining data consistency across microservices.In this vision paper, we argue that there is a need to rethink how database systems can better support microservices and relieve the burden of handling complex data management tasks faced by programmers. We envision the design and research opportunities for a novel distributed database management system targeted at event-driven microservices.},
booktitle = {Proceedings of the 15th ACM International Conference on Distributed and Event-Based Systems},
pages = {25–30},
numpages = {6},
keywords = {database system, microservices, event-driven architecture},
location = {Virtual Event, Italy},
series = {DEBS '21}
}

@inproceedings{10.1145/3123779.3123804,
author = {Haselb\"{o}ck, Stefan and Weinreich, Rainer and Buchgeher, Georg},
title = {Decision Guidance Models for Microservices: Service Discovery and Fault Tolerance},
year = {2017},
isbn = {9781450348430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123779.3123804},
doi = {10.1145/3123779.3123804},
abstract = {Introducing a microservice system is a challenging task and requires the exploration and documentation of several related areas of design. Exploration and documentation of software architecture design is supported by decision guidance models in software architecture. In this paper, we present such guidance models for several microservice system design areas, including service discovery and fault tolerance. The presented models have been created based on existing microservice literature and have been validated and refined in design workshops with business partners as part of a technical action research (TAR) study.},
booktitle = {Proceedings of the Fifth European Conference on the Engineering of Computer-Based Systems},
articleno = {4},
numpages = {10},
keywords = {design decisions, microservices, software architecture, decision guidance models, technical action research (TAR)},
location = {Larnaca, Cyprus},
series = {ECBS '17}
}

@inproceedings{10.1145/3308560.3316509,
author = {W. Collier, Rem and O'Neill, Eoin and Lillis, David and O'Hare, Gregory},
title = {MAMS: Multi-Agent MicroServices✱},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3316509},
doi = {10.1145/3308560.3316509},
abstract = {This paper explores the intersection between microservices and Multi-Agent Systems (MAS), introducing the notion of a new approach to building MAS known as Multi-Agent MicroServices (MAMS). Our approach is illustrated through a worked example of a Vickrey Auction implemented as a microservice.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {655–662},
numpages = {8},
keywords = {text tagging, ACM proceedings},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3147213.3147229,
author = {Torkura, Kennedy A. and Sukmana, Muhammad I.H. and Meinel, Christoph},
title = {Integrating Continuous Security Assessments in Microservices and Cloud Native Applications},
year = {2017},
isbn = {9781450351492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147213.3147229},
doi = {10.1145/3147213.3147229},
abstract = {Cloud Native Applications (CNA) consists of multiple collaborating microservice instances working together towards common goals. These microservices leverage the underlying cloud infrastructure to enable several properties such as scalability and resiliency. CNA are complex distributed applications, vulnerable to several security issues affecting microservices and traditional cloud-based applications. For example, each microservice instance could be developed with different technologies e.g. programming languages and databases. This diversity of technologies increases the chances for security vulnerabilities in microservices. Moreover, the fast-paced development cycles of (CNA) increases the probability of insufficient security tests in the development pipelines, and consequent deployment of vulnerable microservices. Furthermore, cloud native environments are ephemeral, microservices are dynamically launched and de-registered, this factor creates a discoverability challenge for traditional security assessment techniques. Hence, security assessments in such environments require new approaches which are specifically adapted and integrated to CNA. In fact, such techniques are to be cloud native i.e. well integrated into the cloud's fabric. In this paper, we tackle the above-mentioned challenges through the introduction of a novel Security Control concept - the Security Gateway. To support the Security Gateway concept, two other concepts are proposed: dynamic document store and security health endpoints. We have implemented these concepts using cloud-native design patterns and integrated them into the CNA workflow. Our experimental evaluations validate the efficiency of our proposals, the time overhead due to the security gateway is minimal and the vulnerability detection rate surpasses that of traditional security assessment approaches. Our proposal can therefore be employed to secure CNA and microservice-based implementations.},
booktitle = {Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {171–180},
numpages = {10},
keywords = {security assessment, microservices, vulnerability detection, cloud native applications},
location = {Austin, Texas, USA},
series = {UCC '17}
}

@inproceedings{10.1145/3444757.3485108,
author = {Morais, Gabriel and Bork, Dominik and Adda, Mehdi},
title = {Towards an Ontology-Driven Approach to Model and Analyze Microservices Architectures},
year = {2021},
isbn = {9781450383141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3444757.3485108},
doi = {10.1145/3444757.3485108},
abstract = {Microservices Architectures (MSAs) are continuously replacing monolithic systems toward achieving more flexible and maintainable service-oriented software systems. However, the shift toward an MSA also requires a technological and managerial shift for its adopters. Architecting and managing MSAs represent unique challenges, including microservices' identification, interoperability, and reuse. To handle these challenges, we propose an Ontology-driven Conceptual Modelling approach, based on the Ontology of Microservices Architecture Concepts (OMSAC), for modelling and analyzing microservices-based systems. We show, how OMSAC-based conceptual models, stocked in a Stardog triple store, support Stakeholder-specific communication, documentation, and reuse. This paper reports on the application of our approach in three open-source MSA systems with a focus on microservices' discovery based on similarity metrics. Eventually, we compare the extracted similarity metrics derived from the application of machine learning techniques to the OMSAC models with a manual analysis performed by experts.},
booktitle = {Proceedings of the 13th International Conference on Management of Digital EcoSystems},
pages = {79–86},
numpages = {8},
keywords = {ontology, Stardog, Microservices, machine learning, OMSAC},
location = {Virtual Event, Tunisia},
series = {MEDES '21}
}

@inproceedings{10.1145/3379177.3388896,
author = {Wang, Bo and Boehm, Barry W.},
title = {Process Implications of Executable Domain Models for Microservices Development},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388896},
doi = {10.1145/3379177.3388896},
abstract = {Microservice architecture has been recognized as an important enabler for continuous development of many cloud-based systems. Code generation has been tried in the tool chain of building microservices. However, most existing tools generally do not consider the risks from continuous development.We have been developing a toolkit which generates microservices from application domain models. Our approach aligns development process to this toolkit and coordinates domain modeling activity over project life cycles. In this paper, we describe its framework and corresponding development process which eliminates delays brought by the uncertainty of a project at a relatively early stage. Several minimum viable products have been built upon the proposed approach during the past years, including automated generation of code from domain decomposition. Our result shows 10% saving of effort and fewer issues. Effort saving increases to 30% under an extreme condition with high-rate personnel turnover. We also discuss our findings on running these projects and raise discussion and questions for future enhancement.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {41–50},
numpages = {10},
keywords = {code generation, agile, continuous development, domain modeling, microservices},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@article{10.1145/3498336,
author = {Berenberg, Anna and Calder, Brad},
title = {Deployment Archetypes for Cloud Applications},
year = {2022},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3498336},
doi = {10.1145/3498336},
abstract = {This is a survey article that explores six Cloud-based deployment archetypes for Cloud applications and the tradeoffs between them to achieve high availability, low end-user latency, and acceptable costs. These are (1) Zonal, (2) Regional, (3) Multi-regional, (4) Global, (5) Hybrid, and (6) Multi-cloud deployment archetypes. The goal is to classify cloud applications into a set of deployment archetypes and deployment models that tradeoff their needs around availability, latency, and geographical constraints with a focus on serving applications. This enables application owners to better examine the tradeoffs of each deployment model and what is needed for achieving the availability and latency goals for their application.},
journal = {ACM Comput. Surv.},
month = {feb},
articleno = {61},
numpages = {48},
keywords = {cloud architecture, cloud availability, cloud archetypes, Cloud deployments}
}

@inproceedings{10.1145/3342195.3387553,
author = {Sang, Bo and Roman, Pierre-Louis and Eugster, Patrick and Lu, Hui and Ravi, Srivatsan and Petri, Gustavo},
title = {PLASMA: Programmable Elasticity for Stateful Cloud Computing Applications},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342195.3387553},
doi = {10.1145/3342195.3387553},
abstract = {Developers are always on the lookout for simple solutions to manage their applications on cloud platforms. Major cloud providers have already been offering automatic elasticity management solutions (e.g., AWS Lambda, Azure durable function) to users. However, many cloud applications are stateful --- while executing, functions need to share their state with others. Providing elasticity for such stateful functions is much more challenging, as a deployment/elasticity decision for a stateful entity can strongly affect others in ways which are hard to predict without any application knowledge. Existing solutions either only support stateless applications (e.g., AWS Lambda) or only provide limited elasticity management (e.g., Azure durable function) to stateful applications.PLASMA (<u>P</u>rogrammable E<u>la</u>sticity for <u>S</u>tateful Cloud Co<u>m</u>puting <u>A</u>pplications) is a programming framework for elastic stateful cloud applications. It includes (1) an elasticity programming language as a second "level" of programming (complementing the main application programming language) for describing elasticity behavior, and (2) a novel semantics-aware elasticity management runtime that tracks program execution and acts upon application features as suggested by elasticity behavior. We have implemented 10+ applications with PLASMA. Extensive evaluation on Amazon AWS shows that PLASMA significantly improves their efficiency, e.g., achieving same performance as a vanilla setup with 25% fewer resources, or improving performance by 40% compared to the default setup.},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {42},
numpages = {15},
location = {Heraklion, Greece},
series = {EuroSys '20}
}

@inproceedings{10.1145/3147234.3148092,
author = {Martins, Lucas M. C. e and Filho, Francisco L. de Caldas and J\'{u}nior, Rafael T. de Sousa and Giozza, William F. and da Costa, Jo\~{a}o Paulo C.L.},
title = {Increasing the Dependability of IoT Middleware with Cloud Computing and Microservices},
year = {2017},
isbn = {9781450351959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147234.3148092},
doi = {10.1145/3147234.3148092},
abstract = {Internet of Things (IoT) has left the experimental field and is reaching the final consumer in areas such as residential automation, health, transportation and government support. Since these are applications intrinsically linked to the physical world, they require more attention in aspects related to their dependability. Focusing on its availability and reliability, we present a proposal to apply the Microservices architectural pattern in an IoT middleware with web services in the monolithic architecture. We describe the reengineering that must be done in this middleware and, finally, we analyze the advantages and disadvantages of this approach, highlighting the availability improvement, optimization of the infrastructure resources, the ease of maintenance and evolution, as well as the inclination to the elasticity that the architecture allows.},
booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {203–208},
numpages = {6},
keywords = {soa., internet of things (iot), middleware, cloud computing, microservices, dependability},
location = {Austin, Texas, USA},
series = {UCC '17 Companion}
}

@article{10.1145/3381452,
author = {Tsigkanos, Christos and Garriga, Martin and Baresi, Luciano and Ghezzi, Carlo},
title = {Cloud Deployment Tradeoffs for the Analysis of Spatially Distributed Internet of Things Systems},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3381452},
doi = {10.1145/3381452},
abstract = {Internet-enabled devices operating in the physical world are increasingly integrated in modern distributed systems. We focus on systems where the dynamics of spatial distribution is crucial; in such cases, devices may need to carry out complex computations (e.g., analyses) to check satisfaction of spatial requirements. The requirements are partly global—as the overall system should achieve certain goals—and partly individual, as each entity may have different goals. Assurance may be achieved by keeping a model of the system at runtime, monitoring events that lead to changes in the spatial environment, and performing requirements analysis. However, computationally intensive runtime spatial analysis cannot be supported by resource-constrained devices and may be offloaded to the cloud. In such a scenario, multiple challenges arise regarding resource allocation, cost, performance, among other dimensions. In particular, when the workload is unknown at the system’s design time, it may be difficult to guarantee application-service-level agreements, e.g., on response times. To address and reason on these challenges, we first instantiate complex computations as microservices and integrate them to an IoT-cloud architecture. Then, we propose alternative cloud deployments for such an architecture—based on virtual machines, containers, and the recent Functions-as-a-Service paradigm. Finally, we assess the feasibility and tradeoffs of the different deployments in terms of scalability, performance, cost, resource utilization, and more. We adopt a workload scenario from a known dataset of taxis roaming in Beijing, and we derive other workloads to represent unexpected request peaks and troughs. The approach may be replicated in the design process of similar classes of spatially distributed IoT systems.},
journal = {ACM Trans. Internet Technol.},
month = {apr},
articleno = {17},
numpages = {23}
}

@inproceedings{10.1145/3344948.3344952,
author = {Wang, Yuwei},
title = {Towards Service Discovery and Autonomic Version Management in Self-Healing Microservices Architecture},
year = {2019},
isbn = {9781450371421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344948.3344952},
doi = {10.1145/3344948.3344952},
abstract = {Microservices architectures (MSAs) contribute to building complex distributed systems by decomposing monolithic systems into a set of independent microservices. This makes it possible to design, develop and deploy scalable and flexible systems. However, various unexpected changes could happen during execution, such as a service upgrade, a sudden increase of traffic, or an infrastructural failure. In this cases, how to react autonomously to these changes without outages becomes a challenge to consider. A PhD project has been launched to propose a self-healing microservices architecture, which can adapt dynamically to inside and outside changes without human intervention. In this paper, we present the first results of a systematic state of the art in the field of self-healing MSA systems. As an entry point of our research, we focus on self-healing triggered by upgrade changes. The initial contribution is a new component of a version manager in our self-healing MSA solution, in relation with service discovery elements. This approach can provide an autonomic version management on both the application level and the system level, and helps to control services upgrading changes. We plan to validate our proposition in a company project use case by deploying it in an emulated production environment, and applying a chaos engineering approach.},
booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
pages = {63–66},
numpages = {4},
keywords = {industrialization, microservices, version management, software architecture, service discovery, self-healing},
location = {Paris, France},
series = {ECSA '19}
}

@article{10.1145/3418899,
author = {Brondolin, Rolando and Santambrogio, Marco D.},
title = {A Black-Box Monitoring Approach to Measure Microservices Runtime Performance},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3418899},
doi = {10.1145/3418899},
abstract = {Microservices changed cloud computing by moving the applications’ complexity from one monolithic executable to thousands of network interactions between small components. Given the increasing deployment sizes, the architectural exploitation challenges, and the impact on data-centers’ power consumption, we need to efficiently track this complexity. Within this article, we propose a black-box monitoring approach to track microservices at scale, focusing on architectural metrics, power consumption, application performance, and network performance. The proposed approach is transparent w.r.t. the monitored applications, generates less overhead w.r.t. black-box approaches available in the state-of-the-art, and provides fine-grain accurate metrics.},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
articleno = {34},
numpages = {26},
keywords = {performance monitoring, power attribution, kubernetes, network performance monitoring, Microservices, docker, cloud computing}
}

@inproceedings{10.1145/3491204.3527483,
author = {Beck, Samuel and Frank, Sebastian and Hakamian, Alireza and van Hoorn, Andr\'{e}},
title = {How is Transient Behavior Addressed in Practice? Insights from a Series of Expert Interviews},
year = {2022},
isbn = {9781450391597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491204.3527483},
doi = {10.1145/3491204.3527483},
abstract = {Transient behavior occurs when a running software system changes from one steady-state to another. In microservice systems, such disruptions can, for example, be caused by continuous deployment, self-adaptation, and various failures. Although transient behavior could be captured in non-functional requirements, little is known of how that is handled in practice. Our objective was to study how architects and engineers approach runtime disruptions, which challenges they face, whether or not they specify transient behavior, and how currently employed tools and methods can be improved. To this end, we conducted semi-structured interviews with five experienced practitioners from major companies in Germany. We found that a big challenge in the industry is a lack of awareness of transient behavior by software stakeholders. Consequently, they often do not consider specifying it in non-functional requirements. Additionally, better tooling is needed to reduce the effort of analyzing transient behavior. We present two prototypes that we developed corresponding to these findings to improve the current situation. Beyond that, the insights we present can serve as pointers for interesting research directions for other researchers.},
booktitle = {Companion of the 2022 ACM/SPEC International Conference on Performance Engineering},
pages = {105–112},
numpages = {8},
keywords = {transient behavior, non-functional requirements, microservices},
location = {Bejing, China},
series = {ICPE '22}
}

@article{10.1145/3510411,
author = {Korala, Harindu and Georgakopoulos, Dimitrios and Jayaraman, Prem Prakash and Yavari, Ali},
title = {A Survey of Techniques for Fulfilling the Time-Bound Requirements of Time-Sensitive IoT Applications},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {11s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3510411},
doi = {10.1145/3510411},
abstract = {This article surveys existing techniques for meeting the time-bound requirements of time-sensitive applications in the Internet of Things (IoT). To provide the foundation for identifying and classifying relevant techniques, we present three sample time-sensitive IoT applications and their time-bound requirements, describe the main computation and network resources in IoT that can be used to process such applications, and identify the main challenges in meeting their time-bound requirements. Based on these, the article presents a comprehensive literature review of existing techniques and tools that can help meet application-specific time-bound requirements in IoT. The article also includes a gap analysis in existing research outcomes and proposes research directions for bridging the remaining research gaps in supporting time-sensitive IoT applications.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {228},
numpages = {36},
keywords = {Internet of Things (IoT), time sensitive, time-bound}
}

@inproceedings{10.5555/3172795.3172827,
author = {Pourmajidi, William and Steinbacher, John and Erwin, Tony and Miranskyy, Andriy},
title = {On Challenges of Cloud Monitoring},
year = {2017},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cloud services are becoming increasingly popular: 60% of information technology spending in 2016 was Cloud-based, and the size of the public Cloud service market will reach $236B by 2020. To ensure reliable operation of the Cloud services, one must monitor their health.While a number of research challenges in the area of Cloud monitoring have been solved, problems are remaining. This prompted us to highlight three areas, which cause problems to practitioners and require further research. These three areas are as follows: A) defining health states of Cloud systems, B) creating unified monitoring environments, and C) establishing high availability strategies.In this paper we provide details of these areas and suggest a number of potential solutions to the challenges. We also show that Cloud monitoring presents exciting opportunities for novel research and practice.},
booktitle = {Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering},
pages = {259–265},
numpages = {7},
location = {Markham, Ontario, Canada},
series = {CASCON '17}
}

@inproceedings{10.1145/3416505.3423560,
author = {Lomio, Francesco and Baselga, Diego Mart\'{\i}nez and Moreschini, Sergio and Huttunen, Heikki and Taibi, Davide},
title = {RARE: A Labeled Dataset for Cloud-Native Memory Anomalies},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423560},
doi = {10.1145/3416505.3423560},
abstract = {Anomaly detection has been attracting interest from both the industry and the research community for many years, as the number of published papers and services adopted grew exponentially over the last decade. One of the reasons behind this is the wide adoption of cloud systems from the majority of players in multiple industries, such as online shopping, advertisement or remote computing. In this work we propose a Dataset foR cloud-nAtive memoRy anomaliEs: RARE. It includes labelled anomaly time-series data, comprising of over 900 unique metrics. This dataset has been generated using a microservice for injecting artificial byte stream in order to overload the nodes, provoking memory anomalies, which in some cases resulted in a crash. The system was built using a Kafka server deployed on a Kubernetes system. Moreover, in order to get access and download the metrics related to the server, we utilised Prometheus. In this paper we present a dataset that can be used coupled with machine learning algorithms for detecting anomalies in a cloud based system. The dataset will be available in the form of CSV file through an online repository. Moreover, we also included an example of application using a Random Forest algorithm for classifying the data as anomalous or not. The goal of the RARE dataset is to help in the development of more accurate and reliable machine learning methods for anomaly detection in cloud based systems.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {19–24},
numpages = {6},
keywords = {machine learnin, self healing, Dataset, anomaly detection, kubernetes},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@inproceedings{10.1145/3531056.3542769,
author = {Mwotil, Alex and Bainomugisha, Engineer and Araka, Stephen G.M.},
title = {Mira: An Application Containerisation Pipeline for Small Software Development Teams in Low Resource Settings},
year = {2022},
isbn = {9781450396639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531056.3542769},
doi = {10.1145/3531056.3542769},
abstract = {Cloud native applications leverage Development and Operation (DevOps), microservice architectures and containerisation for primarily availability, resilience and scalability reasons. Small developer teams in low resource settings have unique DevOps needs and harnessing its principles and practices is technically challenging and distinctly difficult in these contexts. We conducted a survey with professional developers, students and researchers situated and working in a low resource setting and the results indicate that these principles and practices are relatively new. In application containerisation, an operating system virtualisation method that can significantly optimize the use of computing resources, the respondents indicated challenges in the process steps. Particularly, small developer teams in low resource settings require custom tools and abstractions for software development and delivery automation. Informed by the developer needs, we designed and developed a custom automated containerisation pipeline, mira, for a managed cloud native platform situated in a low-resource setting. We validate mira against 6 major application frameworks, tools and/or languages and successful deployment of the resultant applications onto a cloud native platform.},
booktitle = {Proceedings of the Federated Africa and Middle East Conference on Software Engineering},
pages = {31–38},
numpages = {8},
keywords = {orchestration, docker, cloud, containers, automation, cloud native},
location = {Cairo-Kampala, Egypt},
series = {FAMECSE '22}
}

@inproceedings{10.1145/2993412.3004852,
author = {D\'{\i}az, Jessica and P\'{e}rez, Jennifer and P\'{e}rez, Jorge and Garbajosa, Juan},
title = {Conceptualizing a Framework for Cyber-Physical Systems of Systems Development and Deployment},
year = {2016},
isbn = {9781450347815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993412.3004852},
doi = {10.1145/2993412.3004852},
abstract = {Cyber-physical systems (CPS) refer to the next generation of embedded ICT systems that are interconnected, collaborative and that provide users and businesses with a wide range of smart applications and services. Software in CPS applications ranges from small systems to large systems, aka. Systems of Systems (SoS), such as smart grids and cities. CPSoS require managing massive amounts of data, being aware of their emerging behavior, and scaling out to progressively evolve and add new systems. Cloud computing supports processing and storing massive amounts of data, hosting and delivering services, and configuring self-provisioned resources. Therefore, cloud computing is the natural candidate to solve CPSoS needs. However, the diversity of platforms and the low-level cloud programming models make difficult to find a common solution for the development and deployment of CPSoS. This paper presents the architectural foundations of a cloud-centric framework for automating the development and deployment of CPSoS service applications to converge towards a common open service platform for CPSoS applications. This framework relies on the well-known qualities of the microservices architecture style, the autonomic computing paradigm, and the model-driven software development approach. Its implementation and validation is on-going at two European and national projects.},
booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
articleno = {1},
numpages = {7},
keywords = {microservices, cyber-physical systems, model-driven development, software architecture, cloud computing},
location = {Copenhagen, Denmark},
series = {ECSAW '16}
}

@inproceedings{10.1145/3205651.3208253,
author = {Khalloof, Hatem and Jakob, Wilfried and Liu, Jianlei and Braun, Eric and Shahoud, Shadi and Duepmeier, Clemens and Hagenmeyer, Veit},
title = {A Generic Distributed Microservices and Container Based Framework for Metaheuristic Optimization},
year = {2018},
isbn = {9781450357647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205651.3208253},
doi = {10.1145/3205651.3208253},
abstract = {In recent years, metaheuristics have been a convincing solution for solving many types of complex optimization problems. Efficient execution for the most variants of metaheuristics e.g. Evolutionary Algorithms (EAs) or Swarm Optimization can require lots of computational power depending on the complexity of the application. For maximizing performance, parallelization of metaheuristic algorithms represents a meaningful approach, especially for EAs featuring an inherent parallelism. However, the majority of existing distributed optimization frameworks are implemented as monolithic and non-distributed applications running on one computer instead of using the computing power of computer clusters. Additionally, the application typically cannot easily work dynamically together with other tools and services like single simulators or combinations of simulators for multi-domain simulations. In the present paper, a new distributed framework for population-based metaheuristics, which can run highly parallelized optimizations on large scale computing clusters is introduced. The framework exploits and combines two lightweight technologies namely container virtualization and microservices for a fully automated and highly scalable solution. Another main advantage of the framework is that it allows plugging in and out different metaheuristic optimization algorithms and services via its modular distributed architecture. In order to validate the new design and implementation, the EA GLEAM (General Learning Evolutionary Algorithm and Method) [2, 3] is integrated into the framework and deployed on a cluster with 4 nodes and 128 cores for benchmarking. The tested master-slave parallelization of this EA shows considerable low overhead times and hence paves the way for future applications in, e.g., smart energy systems.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1363–1370},
numpages = {8},
keywords = {scalability, microservices, virtualization, cluster, evolutionary algorithms, parallel computing, container, metaheuristic optimization},
location = {Kyoto, Japan},
series = {GECCO '18}
}

@inproceedings{10.1109/TechDebt.2019.00026,
author = {de Toledo, Saulo S. and Martini, Antonio and Przybyszewska, Agata and Sj\o{}berg, Dag I. K.},
title = {Architectural Technical Debt in Microservices: A Case Study in a Large Company},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/TechDebt.2019.00026},
doi = {10.1109/TechDebt.2019.00026},
abstract = {Introduction: Software companies aim to achieve continuous delivery to constantly provide value to their customers. A popular strategy is to use microservices architecture. However, such an architecture is also subject to debt, which hinders the continuous delivery process and thus negatively affects the software released to the customers.Objectives: The aim of this study is to identify issues, solutions and risks related to Architecture Technical Debt in microservices.Method: We conducted an exploratory case study of a real life project with about 1000 services in a large, international company. Through qualitative analysis of documents and interviews, we investigated Architecture Technical Debt in the communication layer of a system with microservices architecture.Results: Our main contributions are a list of Architecture Technical Debt issues specific for the communication layer in a system with microservices architecture, as well as their associated negative impact (interest), a solution to repay the debt and the its cost (principal). Among the found Architecture Technical Debt issues were the existence of business logic in the communication layer and a high amount of point-to-point connections between services. The studied solution consists of the implementation of different canonical models specific to different domains, the removal of business logic from the communication layer, and migration from services to use the communication layer correctly. We also contributed with a list of possible risks that can affect the payment of the debt, as lack of funding and inadequate prioritization.Conclusion: We found issues, solutions and possible risks that are specific for microservices architectures not yet encountered in the current literature. Our results may be useful for practitioners that want to avoid or repay Technical Debt in their microservices architecture.},
booktitle = {Proceedings of the Second International Conference on Technical Debt},
pages = {78–87},
numpages = {10},
keywords = {microservices, technical debt, case study, architecture},
location = {Montreal, Quebec, Canada},
series = {TechDebt '19}
}

@inproceedings{10.1145/3219819.3219834,
author = {Staar, Peter W J and Dolfi, Michele and Auer, Christoph and Bekas, Costas},
title = {Corpus Conversion Service: A Machine Learning Platform to Ingest Documents at Scale},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219834},
doi = {10.1145/3219819.3219834},
abstract = {Over the past few decades, the amount of scientific articles and technical literature has increased exponentially in size. Consequently, there is a great need for systems that can ingest these documents at scale and make the contained knowledge discoverable. Unfortunately, both the format of these documents (e.g. the PDF format or bitmap images) as well as the presentation of the data (e.g. complex tables) make the extraction of qualitative and quantitive data extremely challenging. In this paper, we present a modular, cloud-based platform to ingest documents at scale. This platform, called the Corpus Conversion Service (CCS), implements a pipeline which allows users to parse and annotate documents (i.e. collect ground-truth), train machine-learning classification algorithms and ultimately convert any type of PDF or bitmap-documents to a structured content representation format. We will show that each of the modules is scalable due to an asynchronous microservice architecture and can therefore handle massive amounts of documents. Furthermore, we will show that our capability to gather groundtruth is accelerated by machine-learning algorithms by at least one order of magnitude. This allows us to both gather large amounts of ground-truth in very little time and obtain very good precision/recall metrics in the range of 99% with regard to content conversion to structured output. The CCS platform is currently deployed on IBM internal infrastructure and serving more than 250 active users for knowledge-engineering project engagements.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {774–782},
numpages = {9},
keywords = {cloud architecture, document conversion, artificial intelligence, knowledge ingestion, ibm, asynchronous architecture, machine learning, ai, table processing, deep learning, cloud computing, pdf, ibm research},
location = {London, United Kingdom},
series = {KDD '18}
}

@article{10.1145/3425866,
author = {Liu, Xuanzhe and Wang, Shangguang and Ma, Yun and Zhang, Ying and Mei, Qiaozhu and Liu, Yunxin and Huang, Gang},
title = {Operating Systems for Resource-Adaptive Intelligent Software: Challenges and Opportunities},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3425866},
doi = {10.1145/3425866},
abstract = {The past decades witnessed the fast and wide deployment of Internet. The Internet has bred the ubiquitous computing environment that is spanning the cloud, edge, mobile devices, and IoT. Software running over such a ubiquitous computing environment environment is eating the world. A recently emerging trend of Internet-based software systems is “resource adaptive,” i.e., software systems should be robust and intelligent enough to the changes of heterogeneous resources, both physical and logical, provided by their running environment. To keep pace of such a trend, we argue that some considerations should be taken into account for the future operating system design and implementation. From the structural perspective, rather than the “monolithic OS” that manages the aggregated resources on the single machine, the OS should be dynamically composed over the distributed resources and flexibly adapt to the resource and environment changes. Meanwhile, the OS should leverage advanced machine/deep learning techniques to derive configurations and policies and automatically learn to tune itself and schedule resources. This article envisions our recent thinking of the new OS abstraction, namely, ServiceOS, for future resource-adaptive intelligent software systems. The idea of ServiceOS is inspired by the delivery model of “Software-as-a-Service” that is supported by the Service-Oriented Architecture (SOA). The key principle of ServiceOS is based on resource disaggregation, resource provisioning as a service, and learning-based resource scheduling and allocation. The major goal of this article is not providing an immediately deployable OS. Instead, we aim to summarize the challenges and potentially promising opportunities and try to provide some practical implications for researchers and practitioners.},
journal = {ACM Trans. Internet Technol.},
month = {mar},
articleno = {27},
numpages = {19},
keywords = {Operating systems, machine learning, service-oriented, resource disaggregation}
}

@proceedings{10.1145/3308560,
title = {WWW '19: Companion Proceedings of The 2019 World Wide Web Conference},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to <i>The Web Conference 2019</i>. The Web Conference is the premier venue focused on understanding the current state and the evolution of the Web through the lens of computer science, computational social science, economics, policy, and many other disciplines. The 2019 edition of the conference is a reflection point as we celebrate the 30th anniversary of the Web.},
location = {San Francisco, USA}
}

@inproceedings{10.1145/3342280.3342287,
author = {Leng, Xue and Juang, Tzung-Han and Chen, Yan and Liu, Han},
title = {AOMO: An AI-Aided Optimizer for Microservices Orchestration},
year = {2019},
isbn = {9781450368865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342280.3342287},
doi = {10.1145/3342280.3342287},
booktitle = {Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos},
pages = {1–2},
numpages = {2},
keywords = {Microservices, Orchestration Optimization},
location = {Beijing, China},
series = {SIGCOMM Posters and Demos '19}
}

@inbook{10.1145/3277669.3277699,
title = {References},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277699},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inproceedings{10.1145/3457784.3457835,
author = {Ahmadi, Ahmadi and Budiardjo, Eko K. and Mahatma, Kodrat},
title = {Software Craftsmanship Skill Using Extreme Programming for Quality Improvement: A Case of Very Small Software Organization},
year = {2021},
isbn = {9781450388825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457784.3457835},
doi = {10.1145/3457784.3457835},
abstract = {Software product release often sacrifices quality concerns and produces messy code to reach the market quickly. At some point, the software becomes difficult to maintain, and reengineering is an available option to improve software quality. By finding a way to improve our software product quality effectively, we explore the available software reengineering methods that match the business needs. This paper presents our case, a product development improvement effort in a very small software organization with limited resources and a tight development schedule. Our research shows that with careful software redesigning and implementing XP practices, supported by a well-crafted software manifesto, we can ensure software code quality improvement is achieved efficiently.},
booktitle = {2021 10th International Conference on Software and Computer Applications},
pages = {94–99},
numpages = {6},
keywords = {very small software organization, software craftsmanship, software reengineering, well-crafted software, software quality, extreme programming},
location = {Kuala Lumpur, Malaysia},
series = {ICSCA 2021}
}

@inbook{10.1145/3277669.3277684,
title = {Reflection on the Kernel},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277684},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277697,
title = {Reaching out to the Future},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277697},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277691,
title = {Putting the Practices Together},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277691},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277672,
title = {From Programming to Software Engineering},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277672},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277689,
title = {Running with Use Case Lite},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277689},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inbook{10.1145/3277669.3277679,
title = {Applying Essence in the Small},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277679},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@book{10.1145/3277669,
author = {Jacobson, Ivar and Lawson, Harold "Bud" and Ng, Pan-Wei and McMahon, Paul E. and Goedicke, Michael},
title = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.}
}

@inbook{10.1145/3277669.3277673,
title = {Software Engineering Methods and Practices},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277673},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@inproceedings{10.1145/3477314.3507221,
author = {M\"{u}ller, Rodrigo H. and Meinhardt, Cristina and Mendizabal, Odorico M.},
title = {An Architecture Proposal for Checkpoint/Restore on Stateful Containers},
year = {2022},
isbn = {9781450387132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477314.3507221},
doi = {10.1145/3477314.3507221},
abstract = {Containers have been widely adopted for the development of microservices and cloud-native applications. In parts, this popularization stems from the container orchestration platforms support, facilitating the development and continuously integrating large-scale applications. However, the established techniques offered by orchestration tools to replicate containers are insufficient to provide high availability and strong consistency for stateful containers. Thus, this paper proposes a Checkpoint/Restore (C/R) service to achieve fault-tolerance on stateful containers. Our service aims to eliminate the checkpoint management burden by adding a transparent C/R service into container orchestration platforms. The checkpointing service, implemented as an interceptor, is responsible for taking snapshots of application containers and coordinating the checkpoint execution with the delivery of requests. In case of faults, a new application container is automatically built from a recent snapshot, and the interceptor resumes the delivery of client requests since that checkpoint. A Proof of Concept using a Kubernetes cluster is implemented and corroborates for the feasibility of the C/R. Some challenges and future directions are discussed.},
booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
pages = {267–270},
numpages = {4},
keywords = {checkpoint/restart, kubernetes, microservices, stateful services},
location = {Virtual Event},
series = {SAC '22}
}

@inbook{10.1145/3277669.3277682,
title = {Developing with Essence},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277682},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@article{10.1145/3267468,
author = {Anisetti, Marco and Ardagna, Claudio and Damiani, Ernesto and Polegri, Gianluca},
title = {Test-Based Security Certification of Composite Services},
year = {2018},
issue_date = {February 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1559-1131},
url = {https://doi.org/10.1145/3267468},
doi = {10.1145/3267468},
abstract = {The diffusion of service-based and cloud-based systems has created a scenario where software is often made available as services, offered as commodities over corporate networks or the global net. This scenario supports the definition of business processes as composite services, which are implemented via either static or runtime composition of offerings provided by different suppliers. Fast and accurate evaluation of services’ security properties becomes then a fundamental requirement and is nowadays part of the software development process. In this article, we show how the verification of security properties of composite services can be handled by test-based security certification and built to be effective and efficient in dynamic composition scenarios. Our approach builds on existing security certification schemes for monolithic services and extends them towards service compositions. It virtually certifies composite services, starting from certificates awarded to the component services. We describe three heuristic algorithms for generating runtime test-based evidence of the composite service holding the properties. These algorithms are compared with the corresponding exhaustive algorithm to evaluate their quality and performance. We also evaluate the proposed approach in a real-world industrial scenario, which considers ENGpay online payment system of Engineering Ingegneria Informatica S.p.A. The proposed industrial evaluation presents the utility and generality of the proposed approach by showing how certification results can be used as a basis to establish compliance to Payment Card Industry Data Security Standard.},
journal = {ACM Trans. Web},
month = {dec},
articleno = {3},
numpages = {43},
keywords = {model-based testing, security certification, Cloud, service-oriented architecture, software-as-a-service, web services, service composition}
}

@inbook{10.1145/3277669.3277678,
title = {Reflection on Theory},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277678},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@article{10.1145/3152529,
author = {Leung, Andrew and Spyker, Andrew and Bozarth, Tim},
title = {Titus: Introducing Containers to the Netflix Cloud},
year = {2018},
issue_date = {February 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {61},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3152529},
doi = {10.1145/3152529},
abstract = {Approaching container adoption in an already cloud-native infrastructure.},
journal = {Commun. ACM},
month = {jan},
pages = {38–45},
numpages = {8}
}

@inproceedings{10.1145/3465481.3470066,
author = {Cavalcanti, Marcos and Inacio, Pedro and Freire, Mario},
title = {Performance Evaluation of Container-Level Anomaly-Based Intrusion Detection Systems for Multi-Tenant Applications Using Machine Learning Algorithms},
year = {2021},
isbn = {9781450390514},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465481.3470066},
doi = {10.1145/3465481.3470066},
abstract = {The virtualization of computing resources provided by containers has gained increasing attention and has been widely used in cloud computing. This new demand for container technology has been growing and the use of Docker and Kubernetes is considerable. According to recent technology surveys, containers are now mainstream. However, currently, one of the major challenges rises from the fact that multiple containers, with different owners, may cohabit on the same host. In container-based multi-tenant environments, security issues are of major concern. In this paper we investigate the performance of container-level anomaly-based intrusion detection systems for multi-tenant applications. We investigate the use of Bag of System Calls (BoSC) technique and the sliding window with the classifier and we consider eight machine learning algorithms for classification purposes. We show that among the eight machine learning algorithms, the best classification results are obtained with Decision Tree and Random Forest which lead to an F-Measure of 99.8%, using a sliding window with a size of 30 and the BoSC algorithm in both cases. We also show that, although both Decision Tree and Random Forest algorithms leads to the best classification results, the Decision Tree algorithm has a shorter execution time and consumes less CPU and memory than the Random Forest.},
booktitle = {Proceedings of the 16th International Conference on Availability, Reliability and Security},
articleno = {109},
numpages = {9},
keywords = {Containers, Machine Learning Algorithms, Intrusion Detection Systems, System Calls},
location = {Vienna, Austria},
series = {ARES 21}
}

@article{10.1145/3155112.3158370,
author = {Leung, Andrew and Spyker, Andrew and Bozarth, Tim},
title = {Titus: Introducing Containers to the Netflix Cloud: Approaching Container Adoption in an Already Cloud-Native Infrastructure},
year = {2017},
issue_date = {September-October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {1542-7730},
url = {https://doi.org/10.1145/3155112.3158370},
doi = {10.1145/3155112.3158370},
abstract = {We believe our approach has enabled Netflix to quickly adopt and benefit from containers. Though the details may be Netflix-specific, the approach of providing low-friction container adoption by integrating with existing infrastructure and working with the right early adopters can be a successful strategy for any organization looking to adopt containers.},
journal = {Queue},
month = {oct},
pages = {53–77},
numpages = {25}
}

@inproceedings{10.5555/3291291.3291321,
author = {Khazaei, Hamzeh and Ghanbari, Alireza and Litoiu, Marin},
title = {Adaptation as a Service},
year = {2018},
publisher = {IBM Corp.},
address = {USA},
abstract = {Current and emerging complex systems of many types including but not limited to big data systems, web-based systems, data centers and cloud infrastructure, social networks and the Internet of Things (IoT) have increasingly distributed and dynamic architecture that provide unprecedented flexibility in creating and supporting applications. However, such highly distributed architecture also increases the complexity of end-to-end management of such systems. Due to the sheer complexity, uncertainty and at the same time programmability of cloud environments, microservices and finally big data analytics, it is now required, and possible, to enable autonomic management in distributed systems in a dependable manner. In this paper, we argue that building autonomic management systems is a challenging task and requires its own set of expertise and knowledge. Therefore, in the light of current challenges, available enablers and recent successful stories, we propose the idea of moving from self-adaptation to ADaptation-as-a-Service (ADaaS).},
booktitle = {Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering},
pages = {282–288},
numpages = {7},
keywords = {microservices, cloud computing, software engineering, eslf-adaptation, containers, adaptation as a service},
location = {Markham, Ontario, Canada},
series = {CASCON '18}
}

@inbook{10.1145/3277669.3277687,
title = {Running with Scrum},
year = {2019},
isbn = {9781947487277},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi.org/10.1145/3277669.3277687},
abstract = {The first course in software engineering is the most critical. Education must start from an understanding of the heart of software development, from familiar ground that is common to all software development endeavors. This book is an in-depth introduction to software engineering that uses a systematic, universal kernel to teach the essential elements of all software engineering methods.This kernel, Essence, is a vocabulary for defining methods and practices. Essence was envisioned and originally created by Ivar Jacobson and his colleagues, developed by Software Engineering Method and Theory (SEMAT) and approved by The Object Management Group (OMG) as a standard in 2014. Essence is a practiceindependent framework for thinking and reasoning about the practices we have and the practices we need. Essence establishes a shared and standard understanding of what is at the heart of software development. Essence is agnostic to any particular method, lifecycle independent, programming language independent, concise, scalable, extensible, and formally specified. Essence frees the practices from their method prisons.The first part of the book describes Essence, the essential elements to work with, the essential things to do and the essential competencies you need when developing software. The other three parts describe more and more advanced use cases of Essence. Using real but manageable examples, it covers the fundamentals of Essence and the innovative use of serious games to support software engineering. It also explains how current practices such as user stories, use cases, Scrum, and microservices can be described using Essence, and illustrates how their activities can be represented using the Essence notions of cards and checklists. The fourth part of the book offers a vision how Essence can be scaled to support large, complex systems engineering.Essence is supported by an ecosystem developed and maintained by a community of experienced people worldwide. From this ecosystem, professors and students can select what they need and create their own way of working, thus learning how to create ONE way of working that matches the particular situation and needs.},
booktitle = {The Essentials of Modern Software Engineering: Free the Practices from the Method Prisons!}
}

@article{10.1145/3539606,
author = {Carri\'{o}n, Carmen},
title = {Kubernetes Scheduling: Taxonomy, Ongoing Issues and Challenges},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3539606},
doi = {10.1145/3539606},
abstract = {Continuous integration enables the development of microservices-based applications using container virtualization technology. Container orchestration systems such as Kubernetes, which has become the de facto standard, simplify the deployment of container-based applications. However, developing efficient and well-defined orchestration systems is a challenge. This paper focuses specifically on the scheduler, a key orchestrator task that assigns physical resources to containers. Scheduling approaches are designed based on different Quality of Service (QoS) parameters to provide limited response time, efficient energy consumption, better resource utilization, and other things. This paper aims to establish insight knowledge into Kubernetes scheduling, find the main gaps, and thus guide future research in the area. Therefore, we conduct a study of empirical research on Kubernetes scheduling techniques and present a new taxonomy for Kubernetes scheduling. The challenges, future direction, and research opportunities are also discussed.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = {may},
keywords = {containers, survey, scheduling, orchestration, Kubernetes}
}

@article{10.1145/3341145,
author = {Duc, Thang Le and Leiva, Rafael Garc\'{\i}a and Casari, Paolo and \"{O}stberg, Per-Olov},
title = {Machine Learning Methods for Reliable Resource Provisioning in Edge-Cloud Computing: A Survey},
year = {2019},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3341145},
doi = {10.1145/3341145},
abstract = {Large-scale software systems are currently designed as distributed entities and deployed in cloud data centers. To overcome the limitations inherent to this type of deployment, applications are increasingly being supplemented with components instantiated closer to the edges of networks—a paradigm known as edge computing. The problem of how to efficiently orchestrate combined edge-cloud applications is, however, incompletely understood, and a wide range of techniques for resource and application management are currently in use.This article investigates the problem of reliable resource provisioning in joint edge-cloud environments, and surveys technologies, mechanisms, and methods that can be used to improve the reliability of distributed applications in diverse and heterogeneous network environments. Due to the complexity of the problem, special emphasis is placed on solutions to the characterization, management, and control of complex distributed applications using machine learning approaches. The survey is structured around a decomposition of the reliable resource provisioning problem into three categories of techniques: workload characterization and prediction, component placement and system consolidation, and application elasticity and remediation. Survey results are presented along with a problem-oriented discussion of the state-of-the-art. A summary of identified challenges and an outline of future research directions are presented to conclude the article.},
journal = {ACM Comput. Surv.},
month = {sep},
articleno = {94},
numpages = {39},
keywords = {placement, consolidation, Reliability, optimization, machine learning, cloud computing, remediation, edge computing, distributed systems, autoscaling}
}

@inproceedings{10.1145/3410992.3410999,
author = {Krivic, Petar and Guberovic, Emanuel and Zarko, Ivana Podnar and Cavrak, Igor},
title = {Evaluation of Selected Technologies for the Implementation of Meter Data Management System},
year = {2020},
isbn = {9781450387583},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410992.3410999},
doi = {10.1145/3410992.3410999},
abstract = {Implementation of an efficient meter data management system presents a challenging task since it has to process and store a large number of incoming time-series data entries in almost real-time. A number of solutions for efficient processing and storage of big data streams are today available as open source or commercial software. However, the choice of the most applicable solution highly depends on the requirements of a specific use case scenario since the performance of the aforementioned solutions often vary depending on the specific use-case parameters (e.g. incoming data frequency, average size of a single data entry, etc.). Thus, in this paper we examine different platforms adequate for the implementation of a smart metering data acquisition system, to identify the most efficient ones among the considered candidates. The most important requirement of our meter data management system is to offer a stable solution that processes and stores high volumes of continuously incoming data readings with minimal loss-rate. For this purpose we propose a modular solution where components communicate over a message-queuing system, while the ultimate data repository is a NoSQL database. After carrying out all the specifically designed performance tests, we identify the following platforms as the most promising ones to implement our smart metering solution: Kafka as the messaging broker and time-series database InfluxDB. Finally, we verified that our MDMS successfully processes and stores 2.5 M data entries in a time period under eight minutes which confirms its targeted performance efficiency.},
booktitle = {Proceedings of the 10th International Conference on the Internet of Things},
articleno = {19},
numpages = {8},
keywords = {smart metering, MDMS, InfluxDB, Kafka, time-series data},
location = {Malm\"{o}, Sweden},
series = {IoT '20}
}

@inproceedings{10.1145/3472883.3486976,
author = {Lim, Soo Yee and Stelea, Bogdan and Han, Xueyuan and Pasquier, Thomas},
title = {Secure Namespaced Kernel Audit for Containers},
year = {2021},
isbn = {9781450386388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472883.3486976},
doi = {10.1145/3472883.3486976},
abstract = {Despite the wide usage of container-based cloud computing, container auditing for security analysis relies mostly on built-in host audit systems, which often lack the ability to capture high-fidelity container logs. State-of-the-art reference-monitor-based audit techniques greatly improve the quality of audit logs, but their system-wide architecture is too costly to be adapted for individual containers. Moreover, these techniques typically require extensive kernel modifications, making it difficult to deploy in practical settings.In this paper, we present saBPF (secure audit BPF), an extension of the eBPF framework capable of deploying secure system-level audit mechanisms at the container granularity. We demonstrate the practicality of saBPF in Kubernetes by designing an audit framework, an intrusion detection system, and a lightweight access control mechanism. We evaluate saBPF and show that it is comparable in performance and security guarantees to audit systems from the literature that are implemented directly in the kernel.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {518–532},
numpages = {15},
keywords = {auditing, provenance, container, eBPF},
location = {Seattle, WA, USA},
series = {SoCC '21}
}

@inproceedings{10.1145/3185768.3186308,
author = {van Eyk, Erwin and Iosup, Alexandru and Abad, Cristina L. and Grohmann, Johannes and Eismann, Simon},
title = {A SPEC RG Cloud Group's Vision on the Performance Challenges of FaaS Cloud Architectures},
year = {2018},
isbn = {9781450356299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3185768.3186308},
doi = {10.1145/3185768.3186308},
abstract = {As a key part of the serverless computing paradigm, Function-as-a-Service (FaaS) platforms enable users to run arbitrary functions without being concerned about operational issues. However, there are several performance-related issues surrounding the state-of-the-art FaaS platforms that can deter widespread adoption of FaaS, including sizeable overheads, unreliable performance, and new forms of the cost-performance trade-off. In this work we, the SPEC RG Cloud Group, identify six performance-related challenges that arise specifically in this FaaS model, and present our roadmap to tackle these problems in the near future. This paper aims at motivating the community to solve these challenges together.},
booktitle = {Companion of the 2018 ACM/SPEC International Conference on Performance Engineering},
pages = {21–24},
numpages = {4},
keywords = {function-as-a-service, FaaS, benchmarking, serverless computing, performance evaluation, reference architecture},
location = {Berlin, Germany},
series = {ICPE '18}
}

@inproceedings{10.1145/3383219.3383276,
author = {Li, Shanshan and Xu, Qianwen and Hou, Peiyu and Chen, Xiudi and Wang, Yanze and Zhang, He and Rong, Guoping},
title = {Exploring the Challenges of Developing and Operating Consortium Blockchains: A Case Study},
year = {2020},
isbn = {9781450377317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383219.3383276},
doi = {10.1145/3383219.3383276},
abstract = {Blockchain and smart contracts are being embraced by more and more industrial practitioners in multiple domains including agriculture, manufacturing, and healthcare. As a distributed, immutable, and partly public ledger, the consortium blockchain demonstrates its potential to enable trustworthy interoperability and collaboration between organizations. However, the mismatch between the unruled software engineering practices and the increased interest of the consortium blockchain technology may pose threats to the quality of systems implemented. To mitigate the possible threats, this study takes the angle of software engineering to systematically understand the challenges and possible solutions in terms of developing and operating a consortium blockchain-based system. For this purpose, we conducted a case study on a typical consortium blockchain-based system and exhaustively collected the data by two rounds in-depth interviews on practitioners of different roles in the case project. Based on the data analysis, eight pairs of challenges and potential solutions were identified, which cover the phases of the development and operation of consortium blockchains. Moreover, we also captured two implications after further analysis of the findings, which worth the special attention of researchers in the near future, i.e. DevOps and microservices for blockchain or smart contracts.},
booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
pages = {398–404},
numpages = {7},
keywords = {DevOps, smart contracts, microservices, Consortium blockchain},
location = {Trondheim, Norway},
series = {EASE '20}
}

